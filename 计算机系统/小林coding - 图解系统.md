[toc]

# 图解系统

## 一、操作系统怎么学？

### 1.1 入门系列

操作系统四个较重要模块：内存管理、进程管理、文件系统管理、输入输出设备管理

《操作系统 - 清华大学》视频

《现代操作系统》

《操作系统 - 哈工大》视频

### 1.2 深入学习系列

《操作系统导论》

《深入理解计算机系统》



## 二、硬件结构

### 2.1 CPU是如何执行程序的？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\程序执行提纲.png)

**1. 图灵机的工作方式**

组成：纸带（内存） + 读写头 + 存储单元（存放数据） + 控制单元（识别字符是数据还是指令） + 运算单元（执行运算指令）

工作流程：读写头读取纸带内容，交给控制单元识别是数据还是运算指令，是数据就存入存储单元中，是运算指令则通知运算单元读取存储单元中的数据进行运算，运算结果最终返回给读写头，读写头再将结果写入纸带格子中。



**2. 冯诺依曼模型**

1945，计算机具体实现，遵循图灵机设计，采用电子元件构造计算机，用二进制计算和存储。

冯诺依曼模型：运算器、控制器、存储器、输入设备、输出设备

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\冯诺依曼模型.png)

**内存**：存储程序和数据，存储基本单位是字节，每个字节对应一个内存地址，内存地址从0编号自增到内存总字节数-1，读写任一个数据速度一样。

**中央处理器**：CPU，常见CPU位宽有32、64，32位CPU一次计算4字节，64位CPU一次计算8字节，位宽越大，可计算的数值就越大。

CPU内部有寄存器、控制单元和逻辑运算单元等，寄存器主要存储计算时数据，提升运算速度。

寄存器分类：

- 通用寄存器：
- 程序计数器：存储CPU下一条执行指令所在内存地址
- 指令寄存器：存储当前正在执行的指令

**总线**：用于CPU和内存以及其他设备之间的通信

- 地址总线
- 数据总线
- 控制总线

当CPU读写内存数据时，通过**地址总线**指定内存地址，**控制总线**控制读或写命令，**数据总线**传输数据。

**输入、输出设备**



**3. 线路位宽与CPU位宽**

线路位宽要能够一次就能访问到所有内存地址，32条地址总线就能操作4G内存

CPU位宽最好不小于线路位宽，32位CPU去加和两个64位数字，需要把64位拆除高低32位分别计算再组合。



**4. 程序执行的基本过程**

CPU指令周期：CPU从程序计数器读取指令、执行、再下一条指令循环

CPU执行程序过程

- CPU读取**程序计数器**的值（指令的内存地址），**控制单元**操作**地址总线**指定要访问的内存地址，内存设备准备好数据后通过**数据总线**将指令数据传给CPU，CPU收到数据后存入**指令寄存器**
- **程序计数器**自增，指向下一条指令。32位位宽CPU，自增4
- CPU分析**指令寄存器**中指令，是计算指令就交给**逻辑运算单元**，是存储指令就交给**控制单元**



**5. a=1+2执行具体过程**

编译器将程序代码编译成汇编代码，汇编器再将其翻译成机器语言。

a = 1 + 2经过编译器分析，数据1和2放在数据段，指令放在正文段。这个运算被翻译成4条指令

- load指令将0x200地址的数据1装入寄存器R0
- load指令将0x204地址的数据2装入寄存器R1
- add指令将R0和R1相加，结果存在寄存器R2
- set指令将R2内容存回0x208（变量a的内存地址）

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\数据段与正文段.png)

**指令**

每条指令有相应机器码，CPU通过解析机器码得知指令内容，不同CPU有不同指令集，也就对应着不同的汇编语言和机器码。

MIPS指令集的指令是32位，高6位代表操作码，表示指令类型，剩余26位根据指令类型各自表示不同内容。主要有R、I、J三种类型

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\MIPS指令集.png)

- R指令：用于算术逻辑，其中有位代表读写的寄存器地址。如果是逻辑位移操作，位移量代表位移的位数。功能码用在操作码不够时进行扩展。
- I指令：用于数据传输、条件分支等。
- J指令：用于跳转。

以add指令为例，add指令属于R指令，操作码是000000，功能码是100000。此时，rs代表第一个寄存器R0编号00000，rt代表第二个寄存器R1编号00001，rd代表目标的临时寄存器R2编号00010。非位移操作，位移量00000。

这条指令的机器码为0x00011020

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\add的MIPS指令.png)

编译器编译程序时会构造指令，即指令编码，而CPU执行程序时要将指令解析，即指令解码。

CPU大多流水线执行指令，将一个任务拆分成多个小任务，通常一条指令分为4个阶段，称4级流水线。这4个阶段称为**指令周期**（Instruction Cycle）

- Fetch：取指令，CPU通过程序计数器从对应内存读取指令到指令寄存器（控制器操作）
- Decode：指令译码，CPU解码指令（控制器操作）
- Execute：执行指令（算术逻辑操作和数据传输、条件分支操作由算术逻辑单元操作，无条件跳转由控制器完成）
- Store：CPU计算结果存回寄存器或寄存器值存入内存

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\CPU指令周期.png)

**指令的类型**

- 数据传输类型的指令：如store/load是寄存器与内存间数据传输指令，mov是将数据在内存地址间移动。
- 运算类型的指令：如加减乘除、位运算、大小比较等，最多处理两个寄存器的数据
- 跳转类型的指令：通过修改程序计数器的值来实现跳转执行指令，如if-else、switch-case、函数调用
- 信号类型的指令：如中断指令trap
- 闲置类型的指令：如指令nop，执行后CPU空转一个周期



**指令的执行速度**

CPU硬件参数GHz代表时钟频率，1GHz时钟频率代表每秒产生1G次脉冲信号，每个脉冲信号高低电平转换是一个时钟周期，CPU在一个时钟周期内能完成一个最基本动作。时钟频率越高，时钟周期越短，工作速度越快。

不同指令时钟周期不同，如加法指令就比乘法指令的时钟周期少。



*程序的CPU执行时间 = CPU时钟周期数（CPU Cycles） x 时钟周期时间（Clock Cycle Time）*

主频越高，时钟周期时间越短，但如今摩尔定律已失效，CPU主频难再翻倍。



*程序的CPU执行时间 = 指令数 x CPI x 时钟周期时间*

- 指令数：通过优化编译器来减少指令
- CPI每条指令平均时钟周期数：通过流水线技术可以让CPI尽可能小
- 时钟周期时间：取决于主频，超频技术将时钟调快但散热压力大



**6. 总结**

只有运算超过32位数值时，64位CPU比32位CPU计算性能好。64为CPU地址总线48位，而32为CPU地址总线只有32位，可寻址内存空间不同。

32位软件的指令为32位，可以通过兼容机制在64位CPU上运行，而64位软件就不能在32位CPU上运行。

硬件64位指CPU位宽，软件64位指指令位宽。



### 2.2 磁盘比内存慢几万倍？

机械硬盘、固态硬盘、内存、寄存器、CPU L1/L2/L3 Cache

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\存储器提纲.png)

**1. 存储器的层次结构**

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\存储区分级.png)

**寄存器**：靠近CPU的控制单元和逻辑计算单元的存储器，数量通常在几十到数百，32位CPU大多寄存器可存储4字节，64位则8字节。寄存器访问速度非常快，一般要求半个CPU时钟周期内读写完成，如果速度太慢会拉长指令处理周期。

**CPU Cache**：用SRAM芯片（静态随机存储器，一断电数据丢失），1个bit需要6个晶体管，所以存储密度不高，但电路简单访问速度非常快。CPU Cache可分L1（一级缓存）、L2（二级缓存）、L3（三级缓存）。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\CPU-Cache.png)

- L1 高速缓存：访问速度几乎和寄存器差不多，2-4个时钟周期，大小几十到几百KB。每个CPU核心有一块L1高速缓存，指令和数据在L1中分开存放，分指令缓存和数据缓存。
- L2 高速缓存：每个CPU核心一块，大小几百KB到几MB，访问速度10-20个时钟周期。
- L3 高速缓存：多个CPU核心共用，大小几到几十MB，访问速度20-60个时钟周期。

**内存**：用DRAM芯片（Dynamic Random Access Memory，动态随机存取存储器），密度比SRAM高，功耗更低，容量更大，造价更低。1bit需要一个晶体管和一个电容，数据存在电容中，电容不断漏电，需要**定时刷新**电容，数据才不会丢失。DRAM数据访问电路和刷新电路都比SRAM更复杂，访问速度更慢，200-300个时钟周期。

**SSD/HDD硬盘**：SSD（Solid-state disk）固态硬盘，结构和内存类似，但断电后数据还在，比内存读写速度慢10-1000倍。机械硬盘HDD（Hard Disk Drive），物理读写方式来访问速度，比内存慢10w倍



**2. 存储器的层次关系**

存储器只和相邻存储器设备打交道，CPU逐层访问存储器去获取数据，存储器分级能够构造缓存体系。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\存储器的层次关系图.png)



**3. 存储器之间的实际价格和性能差距**

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\存储器成本的对比.png)



**4. 总结**



### 2.3 如何写出让CPU跑得更快的代码？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\CPUCache提纲.png)

**1. CPU Cache有多快？**

为什么有内存还要有CPU Cache？CPU访问速度每18个月翻倍，而内存速度跟不上CPU，现在一次内存访问200-300个时钟周期，相差200-300倍。为弥补二者性能差异，在CPU内部引入CPU Cache高速缓存。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\访问速度表格.png)



**2. CPU Cache的数据结构和读取过程是什么样的？**

CPU Cache由很多Cache Line（缓存块）组成，Cache Line是CPU从内存读取数据的基本单位，CPU以一小块一小块的形式读取数据到CPU Cache中（一般64字节）。Cache Line由各种标志（Tag）+ 数据块（Data Block）组成。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\Cache的数据结构.png)

CPU读取数据时先访问Cache，Cache中不存在才去访问内存，内存将数据读入Cache，CPU再从Cache中取。



**直接映射Cache（Direct Mapped Cache）**

CPU从内存一块一块取数据，这块数据称为**内存块**（Block）。

直接映射Cache将内存块的地址映射到一个CPU Cache Line地址，映射关系采用取模运算，如下32个Block映射到8个Cache Line，Block 7、15、23、31都映射到Cache Line 7上。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\求模映射策略.png)

多个Block映射到同一个Cache Line，为此引入**组标记（Tag）**来区分不太同块。

一个内存地址由**组标记、Cache Line索引、偏移量**组成，而CPU Cache的数据结构由**索引、有效位、组标记、数据块**组成。因为CPU读取的数据片段实际上是一个**字（Word）**，而不是整个数据块，因此需要一个偏移量来标记字在数据块中的**偏移量（Offset）**。另外**有效位（Valid bit）**用来标记Cache Line中数据是否有效，如果为0则直接访问内存，重新加载数据。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\直接Cache映射.png)

CPU访问内存地址步骤：

- 根据内存地址的索引确定对应的Cache Line
- 判断对应Cache Line的有效位，无效则直接访问内存，有效则往下
- 对比内存地址中组标记和Cache Line的组标记，不一致则直接访问内存，一致则往下
- 根据内存地址的偏移量，从数据块中取对应字

除了直接映射Cache外，还有全连接Cache、组连接Cache等映射策略。



**3. 如何写出让CPU跑得更快的代码？**

访问Cache比内存快100倍，数据在CPU Cache中意味着**缓存命中**。因此要代码跑的快，就要缓存命中率高。

L1 Cache分数据缓存和指令缓存，因此分别讨论提升数据缓存命中率和指令缓存命中率。

**如何提升数据缓存的命中率？**

例如遍历数组时，如果是跳跃遍历则可能需要反复从内存中读，而如果是按照内存布局顺序访问，则能有效利用Cache带来的好处，提升命中率。

**如何提升指令缓存的命中率？**

例如分支预测器，如果分支预测可以预测到后续要执行到的是if里的指令还是else里的指令，就可以“提前”把指令放在指令缓存中，CPU可以直接从Cache读取到指令。

C/C++编译器提供likely和unlikely两种宏，会将likely修饰的分支代码调整到前面，大概率执行的代码靠前便提高了指令命中率。

```c
#define likely(x) __builtin_expect(!!(x), 1)
#define unlikely(x) __builtin_expect(!!(x), 0)

if (likely(a == 1)) {
    // do something...
} else {
    // do something...
}
```

**如何提升多核CPU的缓存命中率？**

单核CPU只能执行一个线程，操作系统为每个线程分配一个时间片，时间片用完调度下一个线程，各个线程交替占用CPU，宏观上就像多个线程同时执行。

如果一个线程在不同核心间来回切换，会导致各个核心的缓存命中率受影响。对于多个同时执行计算密集型的线程，可以把线程绑定到某个核心上，如Linux提供sched_setaffinity方法将线程绑定到某个CPU核心。

```c
#define _GNU_SOURCE
#include <sched.h>

int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);
```



### 2.4 CPU缓存一致性

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\缓存一致性提纲.png)

**1. CPU Cache的数据写入**

除了从CPU Cache和内存读数据，还有写操作，数据写入Cache后，内存与Cache对应数据将不同，需要将Cache数据同步到内存里。

**写直达（Write Through）**

保持一致最简单的方法，将数据同时写入内存和Cache中。

写入前判断数据是否在CPU Cache里：

- 如果已存在，先将数据更新到Cache里，再写入内存里
- 如果不存在，直接把数据更新到内存里

简单，但是每次写操作都写回内存，花费时间。

**写回（Write Back）**

写回机制中，发生写操作时，新数据仅仅被写入Cache Block里，只有当修改过的Cache Block被替换时才需要写到内存中。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\写回1.png)

只有缓存不命中且数据对应Cache的Cahce Block为脏标记时才将数据写入内存，缓存命中时写入Cache后将数据对应Cache Block标记为脏即可。

写回机制下，读操作和写操作的流程：

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\writeback.png)

**2. 缓存一致性问题**

缓存一致性，指多个核心运行多个线程，但对共同变量进行操作，导致缓存中变量值不一致。

为解决这个问题需要同步不同核心的缓存中数据，为此要保证

- 写传播：更新Cache数据时，传播到其他核心Cache
- 事务串行化：多个核心对同一变量更新，多个更新的写传播先后到达其他核心，导致数据变化顺序不一致，为此要保证事务串行化。

事务串行化，要做到将数据同步其他核心，以及引入**锁**来保证串行化更新数据。



**3. 总线嗅探**

写传播最常见的实现方法是**总线嗅探**。

总线嗅探中，CPU修改变量后将更新事件通过总线通知其他核心，CPU监听总线上的广播，收到事件后检查是否有相同数据在自己的L1 Cache里，有就更新。

总线嗅探中，CPU无时不在监听总线，且不管其他核心是否缓存相同数据，都会广播事件，加重总线负担。

总线嗅探虽然保证了写传播，但是不保证事务串行化。



**4. MESI协议**

MESI协议基于总线嗅探实现了事务串行化，用状态机机制降低总线带宽压力。

MESI协议是4个状态单词的开头字母缩写

- Modified，已修改
- Exclusive，独占
- Shared，共享
- Invalidated， 已失效

四个状态标记Cache Line四个不同的状态，已修改即是脏标记，代表Cache Block里数据已被更新，但没写入内存；已失效，代表Cache Block里数据已失效，不可读；独占和共享状态下，Cache Block里数据和内存数据一致，独占状态时数据只存在一个CPU核心的Cache里，写数据时可以直接写，不存在缓存一致性问题；独占状态下的数据，有其他核心从内存读数据到Cache时，独占状态变为共享，在更新共享的Cache数据时不能直接修改，需要先通知所有其他CPU核心将共享状态转为无效，再更新。

在Cache Line状态是已修改或独占状态时，修改更新其数据不需要广播，减少总线压力。

MESI状态可以用一个有限状态机来表示状态流转

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\MESI协议.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\MESI状态转换表格.png)



### 2.5 CPU是如何执行任务的？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\CPU执行任务提纲.png)

**1. CPU如何读写数据的？**

加载数组里连续多个数据到Cache里时，顺序访问能够提高命中率，但如果使用单独变量，会有Cache伪共享问题。

如下，两个不同核心的线程分别修改不同数据，但是变量A和B是内存连续的，都被读进Cache。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\同一个缓存行.png)

**分析伪共享的问题**

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\分析伪共享1.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\分析伪共享2.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\分析伪共享3.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\分析伪共享4.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\分析伪共享5.png)

像上述交替修改变量A和B时，会重复和内存进行交互，Cache并没有起到缓存效果。

这种多线程同时读写同一个Cache Line的不同变量时，导致CPU Cache失效的现象称为**伪共享（False Sharing）**。



**避免伪共享的方法**

通过避免数据在同一个Cache Line来避免伪共享问题。

Linux内核中`__cacheline_aligned_in_smp`宏定义用来解决伪共享问题，在多核系统中是Cache Line的大小，在单核系统则为空。通过宏定义，使变量在Cache Line里对齐，利用空间换时间，提升性能。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\struct_ab.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\struct_ab1.png)



**2. CPU如何选择线程的？**

Linux内核中进程和线程都是用`task_struct`结构体表示的，区别在于线程`task_struct`结构体内部分资源是共享了进程已创建的资源，如内存地址空间、代码段、文件描述符等，因此Linux线程也称轻量级进程。

没有创建线程的进程只有单个执行流，称为主线程。

Linux内核调度器调度的对象是`task_struct`，称其为**任务**，任务按优先级和响应要求可以分为两种

- 实时任务：对系统响应要求高，要尽快执行，优先级在0-99（数值越小，优先级越高）
- 普通任务：优先级在100-139

**调度类**

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\调度类.png)

Deadline和Realtime调度类用于实时任务，Fair调度类用于普通任务，调度策略有

- SCHED_DEADLINE：按deadline进行调度，距离当前时间最近的deadline任务优先调度
- SCHED_FIFO：相同优先级，先来先服务，但高优先级到来可以抢占低优先级
- SCHED_RR：相同优先级的任务轮流运行一段时间片，用完时间片后放到队尾。高优先级可抢占低优先级
- SCHED_NORMAL：普通任务使用的调度策略
- SCHED_BATCH：后台任务的调度策略，不和终端交互，不影响其他需要交互的任务，可以适当调低优先级

**完全公平调度**

对于普通任务，Linux中实现了一个基于CFS的调度算法，即**完全公平调度（Completely Fair Scheduling）**。

算法理念是让每个任务分配的CPU时间一样。每个任务有一个虚拟运行时间vruntime，任务运行越久，vruntime越大，而CFS算法调度下，优先选vruntime少的任务来保证任务公平性。

普通任务间也存在优先级，vruntime会考虑普通任务的权重，权重和优先级相关。

vruntime += 实际运行时间 \* NICE_0_LOAD / 权重

**CPU运行队列**

每个CPU都有自己的运行队列（Run Queue，rq），用来描述CPU上运行的所有进程，包括三个运行队列，Deadline运行队列dl_rq、实时任务运行队列rt_rq、CFS运行队列cfs_rq。cfs_rq用红黑树描述，按vruntime大小来排序，最左侧叶子节点就是下次被调度的任务。优先级：Deadline > Realtime > Fair。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\CPU队列.png)

**调整优先级**

启动任务时如果没有特意指定优先级，默认都是普通任务，调度类Fair，由CFS调度器管理。

要让普通任务执行更多时间，要调整普通任务优先级，需要通过调整任务的nice值。nice范围-20~19，-20是最高优先级，默认0。nice值映射到优先级范围100-139。

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\优先级.png)



### 2.6 什么是软中断？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\软中断提纲.png)

**1. 中断是什么？**

中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调度内核中的中断处理程序来响应请求。

中断请求的响应程序要尽可能快的执行完，减少对正常进程运行调度的影响。

**2. 什么是软中断？**

执行中断处理程序中可能会暂时关闭中断，如果执行时间过长会导致其他设备中断请求丢失。为此Linux系统将中断过程分为两阶段

- 上半部分：用来快速处理硬件请求（硬中断），一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或时间敏感的事情。
- 下半部分：延迟处理上半部分未完成的工作，一般以内核线程方式运行。由内核触发（软中断）。

硬中断会打断CPU正在执行的任务，然后立即执行中断处理程序，而软中断以内核线程方式运行，每个CPU对应一个软中断内核线程。软中断除了硬件设备中断处理程序的下半部，还有一些内核自定义事件，如内核调度、RCU锁等。

**3. 系统里有哪些软中断？**

Linux中查看`/proc/softirqs`内容可以知晓软中断运行情况，而`/proc/interrupts`是硬中断。

**4. 如何定位软中断CPU使用率过高的问题？**

`top`命令可以查看系统软中断情况，其中`si`项代表CPU在软中断上使用率。`watch -d cat /proc/softirqs`具体查看每个软中断类型的中断次数变化速率。



### 2.7 为什么0.1+0.2不等于0.3？

**1. 为什么负数要用补码表示？**

十进制转二进制采用**除2取余法**。

负数以补码形式表示，补码是正数二进制全部取反后加1。

如果不用补码，只将最高符号位变为1表示负数，那负数的加减法将失效，需要先判断是否为负数，若是负数再将加减法互换，最后再运算。

**2. 十进制小数与二进制的转换**

小数部分转换二进制不同整数，采用**乘2取整法**

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\十进制小数转二进制.png)

由于计算机资源有限，有些小数无法用二进制精确表示，只能用近似值，会有精度缺失。

二进制小数转十进制

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\小数转二进制2.png)



**3. 计算机是怎么存小数的？**

计算机采用浮点数存储小数，1000.101表示为1.000101 x 2^3，即二进制采用科学计数法且规格化。（规格化，小数点左边只有一个数字且整数部分没有前导0）

这种表示下只需要保存000101和3即可表示该数。000101为尾数，3为指数。

IEEE制定的国际标准形式：

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\IEEE标准.png)

- 符号位：0为正数，1为负数
- 指数位：指定了小数点在数据中的位置，可为正数也可以是负数，位数越长表示数值范围越大
- 尾数位：小数点右侧的数字，位数越长表示数值精度越高

单精度浮点数float，双精度浮点数double

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\float.png)

二进制小数转二进制浮点数

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\float存储.png)

小数点右移指数为正，左移为负。偏移量127。

二进制浮点数转二进制小数

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\float公式.png)

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\硬件结构\float转二进制例子.png)

**4. 0.1 + 0.2 == 0.3 ？**

计算机中小数无法完整用二进制表示，只能采用近似数，因此相加结果也是近似数



## 三、操作系统结构

### 3.1 Linux内核 vs Windows内核

**1. 内核**

内核作为应用连接硬件设备的桥梁，应用程序无需关心硬件细节。

现代操作系统，内核一般提供4个基本能力：

- 管理进程、线程，进程调度
- 管理内存，决定内存的分配和回收
- 管理硬件设备，为进程与硬件设备间提供通信能力
- 提供系统调用，使应用程序有更高权限运行

内核有很高权限，可以控制CPU、内存、硬盘等，而应用程序权限很小。大多数操作系统将内存分为两个区域：

- 内核空间：只有内核程序可以访问
- 用户空间：专门给应用程序使用

系统调用可进入内核态

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\操作系统结构\systemcall.png)

**2. Linux的设计**

Linux内核设计理念：

- MultiTask，多任务：单核任务轮流执行一段时间称并发，多核多个任务同时执行称并行
- SMP，对称多处理：每个CPU地位相等，对资源使用权限相同，多个CPU共享同一个内存，每个CPU可以访问完整的内存和硬件资源。SMP决定了每个程序都可以被分配到任意一个CPU上执行。
- ELF，可执行文件链接格式：Linux操作系统中可执行文件的存储格式。
- Monolithic Kernel，宏内核：Linux内核架构就是宏内核，意味Linux的内核是一个完整的可执行程序，具有最高权限。宏内核特征是系统内核的所有模块都运行在内核态，如进程调度、内存管理、文件系统、设备驱动等。此外Linux实现了动态加载内核模块的功能，如设备驱动以可加载形式存在，与其他模块解耦。

微内核相比宏内核，只保留了最基本能力，如进程调度、虚拟机内存、中断等，一些应用放到用户空间，如驱动程序，从而使服务间隔离，这样单个服务被攻击或故障，也不影响其他部分。

混合类型内核，内核里有一个最小版本的微内核，在和其他模块组合成一个宏内核。

**3. Windows设计**

内核为混合类型内核，支持MultiTask和SMP

Windows可执行文件格式是PE，可移植执行文件。



## 四、内存管理

### 4.1 为什么要有虚拟内存？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\虚拟内存提纲.png)

**1. 虚拟内存**

**2. 内存分段**

**3. 内存分页**

**多级页表**

**TLB**

**4. 段页式内存管理**

**5. Linux内存布局**

**6. 总结**



### 4.2 malloc是如何分配内存的？

**1. Linux进程的内存分布长什么样？**

**2. malloc是如何分配内存的？**

**3. malloc()分配的是物理内存吗？**

**4. malloc(1)会分配多大的虚拟内存？**

**5. free释放内存，会归还给操作系统吗？**

**6. 为什么不全部使用mmap来分配内存？**

**7. 既然brk那么牛逼，为什么不全部使用brk来分配？**

**8. free()函数只传入一个内存地址，为什么能知道要释放多大的内存？**



### 4.3 内存满了，会发生什么？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\内存满了会发生什么了-提纲.png)

**1. 内存分配的过程是怎样的？**

**2. 哪些内存可以被回收？**

**3. 回收内存带来的性能影响**

**调整文件页和匿名页的回收倾向**

**尽早触发kswapd内核线程异步回收内存**

**NUMA架构下的内存回收策略**

**4. 如何保护一个进程不被OOM杀掉呢？**

**5. 总结**



### 4.4 在4GB物理内存的机器上，申请8G内存会怎么样？

**1. 操作系统虚拟内存大小**

**32位系统的场景**

**64位系统的场景**

**2. Swap机制的作用**

**实验一：没有开启Swap机制**

**实验二：有开启Swap机制**



### 4.5 如何避免预读失效和缓存污染的问题？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\缓存污染提纲.png)

**1. Linux和MySQL的缓存**

**Linux操作系统的缓存**

**MySQL的缓存**

**2. 传统LRU是如何管理内存数据的？**

**3. 预读失效，怎么办？**

**什么是预读机制？**

**预读失效会带来什么问题？**

**如何避免预读失效造成的影响?**

**4. 缓存污染，怎么办？**

**什么是缓存污染？**

**缓存污染会带来什么问题？**

**咱们避免缓存污染造成的影响？**

**5. 总结**



### 4.6 深入理解Linux虚拟内存管理

![本文概要.png](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\深入理解Linux虚拟内存管理提纲.png)

**1. 到底什么是虚拟内存地址**

**2. 为什么要使用虚拟地址访问内存**

**3. 进程虚拟内存空间**

**4. Linux进程虚拟内存空间**

**4.1 32位机器上进程虚拟内存空间分布**

**4.2 64位机器上进程虚拟内存空间分布**

**5. 进程虚拟内存空间的管理**

**5.1 内核如何划分用户态和内核态虚拟内存空间**

**5.2 内核如何布局进程虚拟内存空间 **

**5.3 内核如何管理虚拟内存区域**

**5.4 定义虚拟内存区域的访问权限和行为规范**

**5.5 关联内存映射中的映射关系**

**5.6 针对虚拟内存区域的相关操作**

**5.7 虚拟内存区域在内核中是如何被组织的**

**6. 程序编译后的二进制文件如何映射到虚拟内存空间中**

**7. 内核虚拟内存空间**

**7.1 32位体系内核虚拟内存空间布局**

**7.1.1 直接映射区**

**7.1.2 ZONE_HIGHMEM高端内存**

**7.1.3 vmalloc动态映射区**

**7.1.4 永久映射区**

**7.1.5 固定映射区**

**7.1.6 临时映射区**

**7.1.7 32位体系结构下Linux虚拟内存空间整体布局**

![image.png](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\Linux虚拟内存空间整体布局.png)

**7.2 64位体系内核虚拟内存空间布局**

**7.2.1 64位体系结构下Linux虚拟内存空间整体布局**

![image.png](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\64位Linux虚拟内存空间整体布局.png)

**8. 到底什么是物理内存地址**

**8.1 DRAM芯片的访问**

**8.2 CPU如何读写主存**

**8.3 CPU从内存读取数据过程**

**8.4 如何根据物理内存地址从主存中读取数据**

**8.5 CPU向内存写入数据过程**



### 4.7 深入理解Linux物理内存管理

**1. 前文回顾**

![本文概要.png](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\内存管理\深入理解Linux物理内存管理提纲.png)

**2. 从CPU角度看物理内存模型**

**2.1 FLATMEM 平坦内存模型**

**2.2 DISCONTIGMEM 非连续内存模型**

**2.3 SPARSEMEM稀疏内存模型**

**2.3.1 物理内存热插拔**

**3. 从CPU角度看物理内存架构**

**3.1 一致性内存访问UMA架构**

**3.2 非一致性内存访问NUMA架构**

**3.2.1 NUMA的内存分配策略**

**3.2.2 NUMA的使用简介**

**3.2.2.1 查看NUMA相关信息**

**3.2.2.2 绑定NUMA节点**

**4. 内核如何管理NUMA节点**

**4.1 内核如何统一组织NUMA节点**

**4.2 NUMA节点描述符pglist_data结构**

**4.3 NUMA节点物理内存区域的划分**

**4.4 NUMA节点中的内存规整与回收**

**4.5 NUMA节点的状态node_states**

**5. 内核如何管理NUMA节点中的物理内存区域**

**5.1 物理内存区域中的预留内存**

**5.2 物理内存区域中的水位线**

**5.3 水位线的计算**

**5.4 min_free_kbytes的计算逻辑**

**5.5 setup_per_zone_wmarks计算水位线**

**5.6 watermark_scale_factor调整水位线的间距**

**5.7 物理内存区域中的冷热页**

**6. 内核如何描述物理内存页**

**6.1 匿名页的反向映射**

**6.2 内存页回收相关属性**

**6.3 物理内存页属性和状态的标志位flag**

**6.4 复合页compound_page相关属性**

**6.5 Slab对象池相关属性**



## 五、进程管理

### 5.1 进程、线程基础知识

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\进程线程提纲.jpg)

**1. 进程**

**进程的状态**

![七种状态变迁](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\进程七中状态.jpg)

**进程的控制结构**

**进程的控制**

**进程的上下文切换**

**2. 线程**

**为什么使用线程？**

**什么是线程？**

**线程与进程的比较**

**线程的上下文切换**

**线程的实现**

**3. 调度**

**调度时机**

**调度原则**

**调度算法**



### 5.2 进程间有哪些通信方法？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\进程间通信提纲.jpg)

**1. 管道**

**2. 消息队列**

**3. 共享内存**

**4. 信号量**

同步信号量、互斥信号量

**5. 信号**

**6. Socket**

**7. 总结**



### 5.3 多线程冲突了怎么办？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\多线程冲突提纲.jpg)

**1. 竞争与协作**

**互斥的概念**

**同步的概念**

**2. 互斥与同步的实现和使用**

**锁**

**信号量**

**生产者-消费者问题**

**3. 经典同步问题**

**哲学家就餐问题**

**读者-写者问题**



### 5.4 怎么避免死锁？

**1. 死锁的概念**

**互斥条件**

**持有并等待条件**

**不可剥夺条件**

**环路等待条件**

**2. 模拟死锁问题的产生**

**3. 利用工具排查死锁问题**

**4. 避免死锁问题的发生**



### 5.5 什么是悲观锁、乐观锁？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\锁之提纲.png)

**1. 互斥锁与自旋锁**

**2. 读写锁**

**3. 乐观锁与悲观锁**



### 5.6 一个进程最多可以创建多少个线程？

### 5.7 线程崩溃了，进程也会崩溃吗？

**1. 线程崩溃，进程一定会崩溃吗**

**2. 进程是如何崩溃的-信号机制简介**

**3. 为什么线程崩溃不会导致JVM进程崩溃**

**4. openJDK源码解析**



## 六、调度算法

### 6.1 进程调度/页面置换/磁盘调度算法

![本文提纲](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\调度算法\调度算法提纲.png)

**1. 进程调度算法**

**先来先服务调度算法**

**最短作业优先调度算法**

**高响应比优先调度算法**

**时间片轮转调度算法**

**最高优先级调度算法**

**多级反馈队列调度算法**

**2. 内存页面置换算法**

![虚拟内存的流程](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\调度算法\虚拟内存管理流程.png)

**最佳页面置换算法**

**先进先出置换算法**

**最近最久未使用的置换算法**

**时钟页面置换算法**

**最不常用算法**



**3. 磁盘调度算法**

**先来先服务**

**最短寻道时间优先**

**扫描算法**

**循环扫描算法**

**LOOK与C-LOOK算法**



## 七、文件系统

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\文件系统\文件系统-提纲.png)

**1. 文件系统的基本组成**

**2. 虚拟文件系统**

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\文件系统\虚拟文件系统.png)

**3. 文件的使用**

**4. 文件的存储**

**连续空间存放方式**

**非连续空间存放方式**

**Unix文件的实现方式**

**5. 空闲空间管理**

**空闲表法**

**空闲链表法**

**位图**

**6. 文件系统的结构**

**7. 目录的存储**

**8. 软链接和硬链接**

**9. 文件I/O**

**缓冲与非缓冲I/O**

**直接与非直接I/O**

**阻塞与非阻塞I/O VS 同步与异步I/O**



### 7.2 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？

**1. Page Cache**

**Page Cache是什么？**

**如何查看系统的Page Cache？**

**page与Page Cache**

**Swap与缺页中断**

**Page Cache与buffer cache**

**Page Cache与预读**

**2. Page Cache与文件持久化的一致性&可靠性**

**3. Page Cache的优劣势**

**Page Cache的优势**

**Page Cache的劣势**



## 八、设备管理

### 8.1 键盘敲入A字母时，操作系统期间发生了什么？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\设备管理\设备管理.png)

**1. 设备控制器**

**2. I/O控制方法**

**3. 设备驱动程序**

**4. 通用块层**

**5. 存储系统I/O软件分层**

**6. 键盘敲入字母时，期间发生了什么？**





## 九、网络系统

### 9.1 什么是零拷贝？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\网络系统\零拷贝提纲.png)

**1. 为什么要有DMA技术？**

**2. 传统的文件传输有多糟糕？**

**3. 如何优化文件传输的性能？**

**4. 如何实现零拷贝？**

**mmap+write**

**sendfile**

**使用零拷贝技术的项目**

**5. PageCache有什么作用？**

**6. 大文件传输用什么方式实现？**




### 9.2 I/O多路复用：select/poll/epoll

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\网络系统\多路复用提纲.png)

**1. 最基本的Socket模型**

**2. 如何服务更多的用户？**

**3. 多进程模型**

**4. 多线程模型**

**5. I/O多路复用**

**6. select/poll**

**7. epoll**

**边缘触发和水平触发**



### 9.3 高性能网络模式：Reactor和Proactor

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\网络系统\reactor提纲.jpeg)

**1. 演进**

**2. Reactor**

**单Reactor单进程/线程**

**单Reactor多线程/多进程**

**多Reactor多进程/线程**

**3. Proactor**



### 9.4 什么是一致性哈希？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\网络系统\一致性哈希提纲.png)

**1. 如何分配请求？**

**2. 使用哈希算法有什么问题？**

**3. 使用一致性哈希算法有什么问题？**

**4. 如何通过虚拟节点提高均衡度？**



## 十、Linux命令

### 10.1 如何查看网络的性能指标？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\Linux命令\网络提纲.png)

**1. 性能指标有哪些？**

**2. 网络配置如何看？**

**3. socket信息如何查看？**

**4. 网络吞吐率和PPS如何查看？**

**5. 连通性和延时如何查看？**



### 10.2 如何从日志分析PV、UV？

![img](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\Linux命令\提纲日志.png)

**1. 别急着开始**

**2. 慎用cat**

**3. PV分析**

**4. PV分组**

**5. UV分析**

**6. UV分组**

**7. 终端分析**

**8. 分析TOP3的请求**

