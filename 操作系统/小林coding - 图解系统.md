[toc]

# 图解系统

## 一、操作系统怎么学？

### 1.1 入门系列

操作系统四个较重要模块：内存管理、进程管理、文件系统管理、输入输出设备管理

《操作系统 - 清华大学》视频

《现代操作系统》

《操作系统 - 哈工大》视频

### 1.2 深入学习系列

《操作系统导论》

《深入理解计算机系统》



## 二、硬件结构

### 2.1 CPU是如何执行程序的？

![img](.\img\硬件结构\程序执行提纲.png)

**1. 图灵机的工作方式**

组成：纸带（内存） + 读写头 + 存储单元（存放数据） + 控制单元（识别字符是数据还是指令） + 运算单元（执行运算指令）

工作流程：读写头读取纸带内容，交给控制单元识别是数据还是运算指令，是数据就存入存储单元中，是运算指令则通知运算单元读取存储单元中的数据进行运算，运算结果最终返回给读写头，读写头再将结果写入纸带格子中。



**2. 冯诺依曼模型**

1945，计算机具体实现，遵循图灵机设计，采用电子元件构造计算机，用二进制计算和存储。

冯诺依曼模型：运算器、控制器、存储器、输入设备、输出设备

![img](.\img\硬件结构\冯诺依曼模型.png)

**内存**：存储程序和数据，存储基本单位是字节，每个字节对应一个内存地址，内存地址从0编号自增到内存总字节数-1，读写任一个数据速度一样。

**中央处理器**：CPU，常见CPU位宽有32、64，32位CPU一次计算4字节，64位CPU一次计算8字节，位宽越大，可计算的数值就越大。

CPU内部有寄存器、控制单元和逻辑运算单元等，寄存器主要存储计算时数据，提升运算速度。

寄存器分类：

- 通用寄存器：
- 程序计数器：存储CPU下一条执行指令所在内存地址
- 指令寄存器：存储当前正在执行的指令

**总线**：用于CPU和内存以及其他设备之间的通信

- 地址总线
- 数据总线
- 控制总线

当CPU读写内存数据时，通过**地址总线**指定内存地址，**控制总线**控制读或写命令，**数据总线**传输数据。

**输入、输出设备**



**3. 线路位宽与CPU位宽**

线路位宽要能够一次就能访问到所有内存地址，32条地址总线就能操作4G内存

**CPU位宽最好不小于线路位宽**，32位CPU去加和两个64位数字，需要把64位拆除高低32位分别计算再组合。



**4. 程序执行的基本过程**

CPU指令周期：CPU从程序计数器读取指令、执行、再下一条指令循环

CPU执行程序过程

- CPU读取**程序计数器**的值（指令的内存地址），**控制单元**操作**地址总线**指定要访问的内存地址，内存设备准备好数据后通过**数据总线**将指令数据传给CPU，CPU收到数据后存入**指令寄存器**
- **程序计数器**自增，指向下一条指令。32位位宽CPU，自增4
- CPU分析**指令寄存器**中指令，是计算指令就交给**逻辑运算单元**，是存储指令就交给**控制单元**



**5. a=1+2执行具体过程**

编译器将程序代码编译成汇编代码，汇编器再将其翻译成机器语言。

a = 1 + 2经过编译器分析，数据1和2放在数据段，指令放在正文段。这个运算被翻译成4条指令

- load指令将0x200地址的数据1装入寄存器R0
- load指令将0x204地址的数据2装入寄存器R1
- add指令将R0和R1相加，结果存在寄存器R2
- set指令将R2内容存回0x208（变量a的内存地址）

![img](.\img\硬件结构\数据段与正文段.png)

**指令**

每条指令有相应机器码，CPU通过解析机器码得知指令内容，不同CPU有不同指令集，也就对应着不同的汇编语言和机器码。

MIPS指令集的指令是32位，高6位代表操作码，表示指令类型，剩余26位根据指令类型各自表示不同内容。主要有R、I、J三种类型

![img](.\img\硬件结构\MIPS指令集.png)

- R指令：用于算术逻辑，其中有位代表读写的寄存器地址。如果是逻辑位移操作，位移量代表位移的位数。功能码用在操作码不够时进行扩展。
- I指令：用于数据传输、条件分支等。
- J指令：用于跳转。

以add指令为例，add指令属于R指令，操作码是000000，功能码是100000。此时，rs代表第一个寄存器R0编号00000，rt代表第二个寄存器R1编号00001，rd代表目标的临时寄存器R2编号00010。非位移操作，位移量00000。

这条指令的机器码为0x00011020

![img](.\img\硬件结构\add的MIPS指令.png)

编译器编译程序时会构造指令，即**指令编码**，而CPU执行程序时要将指令解析，即**指令解码**。

CPU大多流水线执行指令，将一个任务拆分成多个小任务，通常一条指令分为4个阶段，称**4级流水线**。这4个阶段称为**指令周期**（Instruction Cycle）

- Fetch：取指令，CPU通过程序计数器从对应内存读取指令到指令寄存器（控制器操作）
- Decode：指令译码，CPU解码指令（控制器操作）
- Execute：执行指令（算术逻辑操作和数据传输、条件分支操作由算术逻辑单元操作，无条件跳转由控制器完成）
- Store：CPU计算结果存回寄存器或寄存器值存入内存

![img](.\img\硬件结构\CPU指令周期.png)

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E6%8C%87%E4%BB%A4%E5%91%A8%E6%9C%9F%E5%B7%A5%E4%BD%9C%E7%BB%84%E4%BB%B6.png)

**指令的类型**

- 数据传输类型的指令：如store/load是寄存器与内存间数据传输指令，mov是将数据在内存地址间移动。
- 运算类型的指令：如加减乘除、位运算、大小比较等，最多处理两个寄存器的数据
- 跳转类型的指令：通过修改程序计数器的值来实现跳转执行指令，如if-else、switch-case、函数调用
- 信号类型的指令：如中断指令trap
- 闲置类型的指令：如指令nop，执行后CPU空转一个周期



**指令的执行速度**

CPU硬件参数GHz代表时钟频率，1GHz时钟频率代表每秒产生1G次脉冲信号，每个脉冲信号高低电平转换是一个时钟周期，CPU在一个时钟周期内能完成一个最基本动作。时钟频率越高，时钟周期越短，工作速度越快。

不同指令时钟周期不同，如加法指令就比乘法指令的时钟周期少。



*程序的CPU执行时间 = CPU时钟周期数（CPU Cycles） x 时钟周期时间（Clock Cycle Time）*

主频越高，时钟周期时间越短，但如今摩尔定律已失效，CPU主频难再翻倍。



*程序的CPU执行时间 = 指令数 x CPI x 时钟周期时间*

- 指令数：通过优化编译器来减少指令
- CPI每条指令平均时钟周期数：通过流水线技术可以让CPI尽可能小
- 时钟周期时间：取决于主频，超频技术将时钟调快但散热压力大



**6. 总结**

只有运算超过32位数值时，64位CPU比32位CPU计算性能好。**通常64位CPU地址总线48位**，而32为CPU地址总线只有32位，可寻址内存空间不同。

**32位软件的指令为32位，可以通过兼容机制在64位CPU上运行，而64位软件就不能在32位CPU上运行。**

硬件64位指CPU位宽，软件64位指指令位宽。



### 2.2 磁盘比内存慢几万倍？

机械硬盘、固态硬盘、内存、寄存器、CPU L1/L2/L3 Cache

![img](.\img\硬件结构\存储器提纲.png)

**1. 存储器的层次结构**

<img src=".\img\硬件结构\存储区分级.png" alt="img" style="zoom:50%;" />

**寄存器**：靠近CPU的控制单元和逻辑计算单元的存储器，数量通常在几十到数百，32位CPU大多寄存器可存储4字节，64位则8字节。寄存器访问速度非常快，一般要求半个CPU时钟周期内读写完成，如果速度太慢会拉长指令处理周期。

**CPU Cache**：用SRAM芯片（静态随机存储器，一断电数据丢失），1个bit需要6个晶体管，所以存储密度不高，但电路简单访问速度非常快。CPU Cache可分L1（一级缓存）、L2（二级缓存）、L3（三级缓存）。

![img](.\img\硬件结构\CPU-Cache.png)

- L1 高速缓存：访问速度几乎和寄存器差不多，2-4个时钟周期，大小几十到几百KB。每个CPU核心有一块L1高速缓存，指令和数据在L1中分开存放，分指令缓存和数据缓存。
- L2 高速缓存：每个CPU核心一块，大小几百KB到几MB，访问速度10-20个时钟周期。
- L3 高速缓存：多个CPU核心共用，大小几到几十MB，访问速度20-60个时钟周期。

**内存**：用DRAM芯片（Dynamic Random Access Memory，动态随机存取存储器），密度比SRAM高，功耗更低，容量更大，造价更低。1bit需要一个晶体管和一个电容，数据存在电容中，电容不断漏电，需要**定时刷新**电容，数据才不会丢失。DRAM数据访问电路和刷新电路都比SRAM更复杂，访问速度更慢，200-300个时钟周期。

**SSD/HDD硬盘**：SSD（Solid-state disk）固态硬盘，结构和内存类似，但断电后数据还在，比内存读写速度慢10-1000倍。机械硬盘HDD（Hard Disk Drive），物理读写方式来访问速度，比内存慢10w倍



**2. 存储器的层次关系**

存储器只和相邻存储器设备打交道，CPU逐层访问存储器去获取数据，存储器分级能够构造缓存体系。

![img](.\img\硬件结构\存储器的层次关系图.png)



**3. 存储器之间的实际价格和性能差距**

![img](.\img\硬件结构\存储器成本的对比.png)



**4. 总结**



### 2.3 如何写出让CPU跑得更快的代码？

![img](.\img\硬件结构\CPUCache提纲.png)

**1. CPU Cache有多快？**

为什么有内存还要有CPU Cache？CPU访问速度每18个月翻倍，而内存速度跟不上CPU，现在一次内存访问200-300个时钟周期，相差200-300倍。为弥补二者性能差异，在CPU内部引入CPU Cache高速缓存。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E7%BC%93%E5%AD%98/%E6%9F%A5%E7%9C%8BCPU%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%A4%A7%E5%B0%8F.png)

![img](.\img\硬件结构\访问速度表格.png)



**2. CPU Cache的数据结构和读取过程是什么样的？**

CPU Cache由很多Cache Line（缓存块）组成，Cache Line是CPU从内存读取数据的基本单位，CPU以一小块一小块的形式读取数据到CPU Cache中（一般64字节）。Cache Line由各种标志（Tag）+ 数据块（Data Block）组成。

![img](.\img\硬件结构\Cache的数据结构.png)

CPU读取数据时先访问Cache，Cache中不存在才去访问内存，内存将数据读入Cache，CPU再从Cache中取。



**直接映射Cache（Direct Mapped Cache）**

CPU从内存一块一块取数据，这块数据称为**内存块**（Block）。

直接映射Cache将内存块的地址映射到一个CPU Cache Line地址，映射关系采用取模运算，如下32个Block映射到8个Cache Line，Block 7、15、23、31都映射到Cache Line 7上。

![img](.\img\硬件结构\求模映射策略.png)

多个Block映射到同一个Cache Line，为此引入**组标记（Tag）**来区分不太同块。

一个内存地址由**组标记、Cache Line索引、偏移量**组成，而CPU Cache的数据结构由**索引、有效位、组标记、数据块**组成。因为CPU读取的数据片段实际上是一个**字（Word）**，而不是整个数据块，因此需要一个偏移量来标记字在数据块中的**偏移量（Offset）**。另外**有效位（Valid bit）**用来标记Cache Line中数据是否有效，如果为0则直接访问内存，重新加载数据。

![img](.\img\硬件结构\直接Cache映射.png)

CPU访问内存地址步骤：

- 根据内存地址的索引确定对应的Cache Line
- 判断对应Cache Line的有效位，无效则直接访问内存，有效则往下
- 对比内存地址中组标记和Cache Line的组标记，不一致则直接访问内存，一致则往下
- 根据内存地址的偏移量，从数据块中取对应字

除了直接映射Cache外，还有全连接Cache、组连接Cache等映射策略。



**3. 如何写出让CPU跑得更快的代码？**

访问Cache比内存快100倍，数据在CPU Cache中意味着**缓存命中**。因此要代码跑的快，就要缓存命中率高。

L1 Cache分数据缓存和指令缓存，因此分别讨论提升数据缓存命中率和指令缓存命中率。

**如何提升数据缓存的命中率？**

例如遍历数组时，如果是跳跃遍历则可能需要反复从内存中读，而如果是按照内存布局顺序访问，则能有效利用Cache带来的好处，提升命中率。

**如何提升指令缓存的命中率？**

例如分支预测器，如果分支预测可以预测到后续要执行到的是if里的指令还是else里的指令，就可以“提前”把指令放在指令缓存中，CPU可以直接从Cache读取到指令。

C/C++编译器提供likely和unlikely两种宏，会将likely修饰的分支代码调整到前面，大概率执行的代码靠前便提高了指令命中率。

```c
#define likely(x) __builtin_expect(!!(x), 1)
#define unlikely(x) __builtin_expect(!!(x), 0)

if (likely(a == 1)) {
    // do something...
} else {
    // do something...
}
```

**如何提升多核CPU的缓存命中率？**

单核CPU只能执行一个线程，操作系统为每个线程分配一个时间片，时间片用完调度下一个线程，各个线程交替占用CPU，宏观上就像多个线程同时执行。

如果一个线程在不同核心间来回切换，会导致各个核心的缓存命中率受影响。对于多个同时执行计算密集型的线程，可以把线程绑定到某个核心上，如Linux提供sched_setaffinity方法将线程绑定到某个CPU核心。

```c
#define _GNU_SOURCE
#include <sched.h>

int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);
```



### 2.4 CPU缓存一致性

![img](.\img\硬件结构\缓存一致性提纲.png)

**1. CPU Cache的数据写入**

除了从CPU Cache和内存读数据，还有写操作，数据写入Cache后，内存与Cache对应数据将不同，需要将Cache数据同步到内存里。

**写直达（Write Through）**

保持一致最简单的方法，将数据同时写入内存和Cache中。

写入前判断数据是否在CPU Cache里：

- 如果已存在，先将数据更新到Cache里，再写入内存里
- 如果不存在，直接把数据更新到内存里

简单，但是每次写操作都写回内存，花费时间。

**写回（Write Back）**

写回机制中，发生写操作时，新数据仅仅被写入Cache Block里，只有当修改过的Cache Block被替换时才需要写到内存中。

<img src=".\img\硬件结构\写回1.png" alt="img" style="zoom:50%;" />

只有缓存不命中且数据对应Cache的Cahce Block为脏标记时才将数据写入内存，缓存命中时写入Cache后将数据对应Cache Block标记为脏即可。

写回机制下，读操作和写操作的流程：

![img](.\img\硬件结构\writeback.png)

**2. 缓存一致性问题**

缓存一致性，指多个核心运行多个线程，但对共同变量进行操作，导致缓存中变量值不一致。

为解决这个问题需要同步不同核心的缓存中数据，为此要保证

- 写传播：更新Cache数据时，传播到其他核心Cache
- 事务串行化：多个核心对同一变量更新，多个更新的写传播先后到达其他核心，导致数据变化顺序不一致，为此要保证事务串行化。

事务串行化，要做到将数据同步其他核心，以及引入**锁**来保证串行化更新数据。



**3. 总线嗅探**

写传播最常见的实现方法是**总线嗅探（Bus Snooping）**。

总线嗅探中，CPU修改变量后将更新事件通过总线通知其他核心，CPU监听总线上的广播，收到事件后检查是否有相同数据在自己的L1 Cache里，有就更新。

总线嗅探中，CPU无时不在监听总线，且不管其他核心是否缓存相同数据，都会广播事件，加重总线负担。

总线嗅探虽然保证了写传播，但是不保证事务串行化。



**4. MESI协议**

MESI协议基于总线嗅探实现了事务串行化，用状态机机制降低总线带宽压力。

MESI协议是4个状态单词的开头字母缩写

- Modified，已修改
- Exclusive，独占
- Shared，共享
- Invalidated， 已失效

四个状态标记Cache Line四个不同的状态，已修改即是脏标记，代表Cache Block里数据已被更新，但没写入内存；已失效，代表Cache Block里数据已失效，不可读；独占和共享状态下，Cache Block里数据和内存数据一致，独占状态时数据只存在一个CPU核心的Cache里，写数据时可以直接写，不存在缓存一致性问题；独占状态下的数据，有其他核心从内存读数据到Cache时，独占状态变为共享，在更新共享的Cache数据时不能直接修改，需要先通知所有其他CPU核心将共享状态转为无效，再更新。

在Cache Line状态是已修改或独占状态时，修改更新其数据不需要广播，减少总线压力。

MESI状态可以用一个有限状态机来表示状态流转

![img](.\img\硬件结构\MESI协议.png)

![img](.\img\硬件结构\MESI状态转换表格.png)



### 2.5 CPU是如何执行任务的？

![img](.\img\硬件结构\CPU执行任务提纲.png)

**1. CPU如何读写数据的？**

加载数组里连续多个数据到Cache里时，顺序访问能够提高命中率，但如果使用单独变量，会有Cache伪共享问题。

如下，两个不同核心的线程分别修改不同数据，但是变量A和B是内存连续的，都被读进Cache。

![img](.\img\硬件结构\同一个缓存行.png)

**分析伪共享的问题**

![img](.\img\硬件结构\分析伪共享1.png)

![img](.\img\硬件结构\分析伪共享2.png)

![img](.\img\硬件结构\分析伪共享3.png)

![img](.\img\硬件结构\分析伪共享4.png)

![img](.\img\硬件结构\分析伪共享5.png)

像上述交替修改变量A和B时，会重复和内存进行交互，Cache并没有起到缓存效果。

这种**多线程同时读写同一个Cache Line的不同变量**时，导致CPU Cache失效的现象称为**伪共享（False Sharing）**。



**避免伪共享的方法**

通过**避免数据在同一个Cache Line**来避免伪共享问题。

Linux内核中`__cacheline_aligned_in_smp`宏定义用来解决伪共享问题，在多核系统中是Cache Line的大小，在单核系统则为空。通过宏定义，使变量在Cache Line里对齐，利用**空间换时间**，提升性能。

![img](.\img\硬件结构\struct_ab.png)

![img](.\img\硬件结构\struct_ab1.png)

避免方法

- Cache Line大小字节对齐
- 字节填充



**2. CPU如何选择线程的？**

Linux内核中进程和线程都是用`task_struct`结构体表示的，区别在于线程`task_struct`结构体内**部分资源是共享了进程已创建的资源**，如内存地址空间、代码段、文件描述符等，因此Linux线程也称轻量级进程。

**没有创建线程的进程只有单个执行流，称为主线程**。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost3@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/CPU%E4%BC%AA%E5%85%B1%E4%BA%AB/%E4%BB%BB%E5%8A%A1.png)

Linux**内核调度器**调度的对象是`task_struct`，称其为**任务**，任务按优先级和响应要求可以分为两种

- 实时任务：对系统响应要求高，要尽快执行，优先级在0-99（数值越小，优先级越高）
- 普通任务：优先级在100-139

**调度类**

![img](.\img\硬件结构\调度类.png)

Deadline和Realtime调度类用于实时任务，Fair调度类用于普通任务，调度策略有

- SCHED_DEADLINE：按deadline进行调度，距离当前时间最近的deadline任务优先调度
- SCHED_FIFO：相同优先级，先来先服务，但高优先级到来可以抢占低优先级
- SCHED_RR：相同优先级的任务轮流运行一段时间片，用完时间片后放到队尾。高优先级可抢占低优先级
- SCHED_NORMAL：普通任务使用的调度策略
- SCHED_BATCH：后台任务的调度策略，不和终端交互，不影响其他需要交互的任务，可以适当调低优先级

**完全公平调度**

对于普通任务，Linux中实现了一个基于CFS的调度算法，即**完全公平调度（Completely Fair Scheduling）**。

算法理念是让每个任务分配的CPU时间一样。每个任务有一个虚拟运行时间vruntime，任务运行越久，vruntime越大，而CFS算法调度下，**优先选vruntime少的任务来保证任务公平性**。

普通任务间也存在优先级，vruntime会考虑普通任务的权重，权重和优先级相关，任务的nice值越低（优先级越大），则权重越大。NICE_0_LOAD为常量。

vruntime += 实际运行时间 \* NICE_0_LOAD / 权重

**CPU运行队列**

每个CPU都有自己的运行队列（Run Queue，rq），用来描述CPU上运行的所有进程，rq包括三个运行队列，Deadline运行队列dl_rq、实时任务运行队列rt_rq、CFS运行队列cfs_rq。cfs_rq用红黑树描述（红黑树是一种平衡二叉搜索树），按vruntime大小来排序，最左侧叶子节点就是下次被调度的任务。优先级：Deadline > Realtime > Fair。

![img](.\img\硬件结构\CPU队列.png)

**调整优先级**

启动任务时如果没有特意指定优先级，默认都是普通任务，调度类Fair，由CFS调度器管理。

要让普通任务执行更多时间，要调整普通任务优先级，需要通过调整任务的nice值。nice范围-20~19，-20是最高优先级，默认0。nice值映射到优先级范围100-139。

![img](.\img\硬件结构\优先级.png)



### 2.6 什么是软中断？

![img](.\img\硬件结构\软中断提纲.png)

**1. 中断是什么？**

中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调度内核中的中断处理程序来响应请求。

中断请求的响应程序要尽可能快的执行完，减少对正常进程运行调度的影响。

**2. 什么是软中断？**

执行中断处理程序中可能会暂时关闭中断，如果执行时间过长会导致其他设备中断请求丢失。为此Linux系统将中断过程分为两阶段

- 上半部分：用来快速处理硬件请求（硬中断），一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或时间敏感的事情。
- 下半部分：延迟处理上半部分未完成的工作，一般以内核线程方式运行。由内核触发（软中断）。

硬中断会打断CPU正在执行的任务，然后立即执行中断处理程序，而软中断以内核线程方式运行，每个CPU对应一个软中断内核线程，通常命名[ksoftirqd/CPU编号]，如0号CPU对应`ksoftirqd/0`。软中断除了硬件设备中断处理程序的下半部，还有一些内核自定义事件，如内核调度、RCU锁等。

**3. 系统里有哪些软中断？**

Linux中查看`/proc/softirqs`内容可以知晓软中断运行情况，而`/proc/interrupts`是硬中断。

软中断类型如TIMER定时中断、NET_RX网络接收中断、NET_TX网络发送中断、RCU锁中断、SCHED内核调度中断等。

**4. 如何定位软中断CPU使用率过高的问题？**

`top`命令可以查看系统软中断情况，其中`si`项代表CPU在软中断上使用率。`watch -d cat /proc/softirqs`具体查看每个软中断类型的中断次数变化速率。

对于网络I/O较高的Web服务器，NET_RX变化速率会相对较快。过快时可以使用`sar -n DEV`查看网卡的网络包接收速率情况，再通过tcpdump抓包分析来源，非法地址可以用防火墙拦截。

### 2.7 为什么0.1+0.2不等于0.3？

**1. 为什么负数要用补码表示？**

十进制转二进制采用**除2取余法**。

负数以补码形式表示，补码是正数二进制全部取反后加1。

如果不用补码，只将最高符号位变为1表示负数，那负数的加减法将失效，需要先判断是否为负数，若是负数再将加减法互换，最后再运算。

**2. 十进制小数与二进制的转换**

小数部分转换二进制不同整数，采用**乘2取整法**

![img](.\img\硬件结构\十进制小数转二进制.png)

由于计算机资源有限，有些小数无法用二进制精确表示，只能用近似值，会有精度缺失。

二进制小数转十进制

![img](.\img\硬件结构\小数转二进制2.png)



**3. 计算机是怎么存小数的？**

计算机采用浮点数存储小数，1000.101表示为1.000101 x 2^3，即二进制采用科学计数法且规格化。（规格化，小数点左边只有一个数字且整数部分没有前导0）

这种表示下只需要保存000101和3即可表示该数。000101为尾数，3为指数。

IEEE制定的国际标准形式：

![img](.\img\硬件结构\IEEE标准.png)

- 符号位：0为正数，1为负数
- 指数位：指定了小数点在数据中的位置，可为正数也可以是负数，位数越长表示数值范围越大
- 尾数位：小数点右侧的数字，位数越长表示数值精度越高

单精度浮点数float，双精度浮点数double

![img](.\img\硬件结构\float.png)

二进制小数转二进制浮点数

![img](.\img\硬件结构\float存储.png)

小数点左移指数为正，右移为负。偏移量127。

二进制浮点数转二进制小数

![img](.\img\硬件结构\float公式.png)

![img](.\img\硬件结构\float转二进制例子.png)

**4. 0.1 + 0.2 == 0.3 ？**

计算机中小数无法完整用二进制表示，只能采用近似数，因此相加结果也是近似数



## 三、操作系统结构

### 3.1 Linux内核 vs Windows内核

**1. 内核**

内核作为应用连接硬件设备的桥梁，应用程序无需关心硬件细节。

现代操作系统，内核一般提供**4个基本能力**：

- 进程调度：管理进程、线程
- 内存管理：决定内存的分配和回收
- 硬件通信：管理硬件设备，为进程与硬件设备间提供通信能力
- 系统调用：使应用程序有更高权限运行

内核有很高权限，可以控制CPU、内存、硬盘等，而应用程序权限很小。大多数操作系统将内存分为两个区域：

- 内核空间：只有内核程序可以访问
- 用户空间：专门给应用程序使用

程序进入内核态可以访问所有内存空间，处于用户态只能访问当前用户空间。

**系统调用可进入内核态**

![img](.\img\操作系统结构\systemcall.png)

**2. Linux的设计**

Linux内核设计理念：

- **MultiTask**，多任务：单核任务轮流执行一段时间称**并发**，多核多个任务同时执行称**并行**

- **SMP**，对称多处理：每个CPU地位相等，对资源使用权限相同，多个CPU共享同一个内存，每个CPU可以访问完整的内存和硬件资源。SMP决定了每个程序都可以被分配到任意一个CPU上执行。

- **ELF**，可执行文件链接格式：Linux操作系统中可执行文件的存储格式。代码通过【编译器】编译成汇编代码，通过【汇编器】转出目标代码，通过【链接器】把多个目标文件及各种函数库链接起来形成可执行文件，通过【装载器】加载入内存，CPU读取内存中的指令和数据来执行程序。

- Monolithic Kernel，**宏内核**：Linux内核架构就是宏内核，意味Linux的内核是一个完整的可执行程序，具有最高权限。**宏内核特征是系统内核的所有模块都运行在内核态**，如进程调度、内存管理、文件系统、设备驱动等。此外Linux实现了**动态加载内核模块**的功能，如设备驱动以可加载形式存在，与其他模块解耦。

  **微内核**相比宏内核，只保留了最基本能力，如进程调度、虚拟机内存、中断等，一些应用放到用户空间，如驱动程序，从而使服务间**隔离**，这样单个服务被攻击或故障，也不影响其他部分。

  **混合类型内核**，内核里有一个最小版本的微内核，在和其他模块组合成一个宏内核。

  ![分别为宏内核、微内核、混合内核的操作系统结构](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E5%86%85%E6%A0%B8/OS-structure2.png)



**3. Windows设计**

win7、win10都用**Windows NT**内核（New Technology）

内核为**混合类型内核**，支持MultiTask和SMP

Windows可执行文件格式是**PE**，可移植执行文件（扩展名.exe、.dll、.sys等）。

**4. 总结**

宏内核、微内核、混合内核

Linux（宏内核，ELF可执行文件格式）、Windows（混合内核，PE可执行文件格式）



## 四、内存管理

### 4.1 为什么要有虚拟内存？

![img](.\img\内存管理\虚拟内存提纲.png)

**1. 虚拟内存**

**2. 内存分段**

**3. 内存分页**

**多级页表**

**TLB**

**4. 段页式内存管理**

**5. Linux内存布局**

**6. 总结**



### 4.2 malloc是如何分配内存的？

**1. Linux进程的内存分布长什么样？**

**2. malloc是如何分配内存的？**

**3. malloc()分配的是物理内存吗？**

**4. malloc(1)会分配多大的虚拟内存？**

**5. free释放内存，会归还给操作系统吗？**

**6. 为什么不全部使用mmap来分配内存？**

**7. 既然brk那么牛逼，为什么不全部使用brk来分配？**

**8. free()函数只传入一个内存地址，为什么能知道要释放多大的内存？**



### 4.3 内存满了，会发生什么？

![img](.\img\内存管理\内存满了会发生什么了-提纲.png)

**1. 内存分配的过程是怎样的？**

**2. 哪些内存可以被回收？**

**3. 回收内存带来的性能影响**

**调整文件页和匿名页的回收倾向**

**尽早触发kswapd内核线程异步回收内存**

**NUMA架构下的内存回收策略**

**4. 如何保护一个进程不被OOM杀掉呢？**

**5. 总结**



### 4.4 在4GB物理内存的机器上，申请8G内存会怎么样？

**1. 操作系统虚拟内存大小**

**32位系统的场景**

**64位系统的场景**

**2. Swap机制的作用**

**实验一：没有开启Swap机制**

**实验二：有开启Swap机制**



### 4.5 如何避免预读失效和缓存污染的问题？

![img](.\img\内存管理\缓存污染提纲.png)

**1. Linux和MySQL的缓存**

**Linux操作系统的缓存**

**MySQL的缓存**

**2. 传统LRU是如何管理内存数据的？**

**3. 预读失效，怎么办？**

**什么是预读机制？**

**预读失效会带来什么问题？**

**如何避免预读失效造成的影响?**

**4. 缓存污染，怎么办？**

**什么是缓存污染？**

**缓存污染会带来什么问题？**

**咱们避免缓存污染造成的影响？**

**5. 总结**



### 4.6 深入理解Linux虚拟内存管理

![本文概要.png](.\img\内存管理\深入理解Linux虚拟内存管理提纲.png)

**1. 到底什么是虚拟内存地址**

**2. 为什么要使用虚拟地址访问内存**

**3. 进程虚拟内存空间**

**4. Linux进程虚拟内存空间**

**4.1 32位机器上进程虚拟内存空间分布**

**4.2 64位机器上进程虚拟内存空间分布**

**5. 进程虚拟内存空间的管理**

**5.1 内核如何划分用户态和内核态虚拟内存空间**

**5.2 内核如何布局进程虚拟内存空间 **

**5.3 内核如何管理虚拟内存区域**

**5.4 定义虚拟内存区域的访问权限和行为规范**

**5.5 关联内存映射中的映射关系**

**5.6 针对虚拟内存区域的相关操作**

**5.7 虚拟内存区域在内核中是如何被组织的**

**6. 程序编译后的二进制文件如何映射到虚拟内存空间中**

**7. 内核虚拟内存空间**

**7.1 32位体系内核虚拟内存空间布局**

**7.1.1 直接映射区**

**7.1.2 ZONE_HIGHMEM高端内存**

**7.1.3 vmalloc动态映射区**

**7.1.4 永久映射区**

**7.1.5 固定映射区**

**7.1.6 临时映射区**

**7.1.7 32位体系结构下Linux虚拟内存空间整体布局**

![image.png](.\img\内存管理\Linux虚拟内存空间整体布局.png)

**7.2 64位体系内核虚拟内存空间布局**

**7.2.1 64位体系结构下Linux虚拟内存空间整体布局**

![image.png](.\img\内存管理\64位Linux虚拟内存空间整体布局.png)

**8. 到底什么是物理内存地址**

**8.1 DRAM芯片的访问**

**8.2 CPU如何读写主存**

**8.3 CPU从内存读取数据过程**

**8.4 如何根据物理内存地址从主存中读取数据**

**8.5 CPU向内存写入数据过程**



### 4.7 深入理解Linux物理内存管理

**1. 前文回顾**

![本文概要.png](.\img\内存管理\深入理解Linux物理内存管理提纲.png)

**2. 从CPU角度看物理内存模型**

**2.1 FLATMEM 平坦内存模型**

**2.2 DISCONTIGMEM 非连续内存模型**

**2.3 SPARSEMEM稀疏内存模型**

**2.3.1 物理内存热插拔**

**3. 从CPU角度看物理内存架构**

**3.1 一致性内存访问UMA架构**

**3.2 非一致性内存访问NUMA架构**

**3.2.1 NUMA的内存分配策略**

**3.2.2 NUMA的使用简介**

**3.2.2.1 查看NUMA相关信息**

**3.2.2.2 绑定NUMA节点**

**4. 内核如何管理NUMA节点**

**4.1 内核如何统一组织NUMA节点**

**4.2 NUMA节点描述符pglist_data结构**

**4.3 NUMA节点物理内存区域的划分**

**4.4 NUMA节点中的内存规整与回收**

**4.5 NUMA节点的状态node_states**

**5. 内核如何管理NUMA节点中的物理内存区域**

**5.1 物理内存区域中的预留内存**

**5.2 物理内存区域中的水位线**

**5.3 水位线的计算**

**5.4 min_free_kbytes的计算逻辑**

**5.5 setup_per_zone_wmarks计算水位线**

**5.6 watermark_scale_factor调整水位线的间距**

**5.7 物理内存区域中的冷热页**

**6. 内核如何描述物理内存页**

**6.1 匿名页的反向映射**

**6.2 内存页回收相关属性**

**6.3 物理内存页属性和状态的标志位flag**

**6.4 复合页compound_page相关属性**

**6.5 Slab对象池相关属性**



## 五、进程管理

### 5.1 进程、线程基础知识

![img](.\img\进程管理\进程线程提纲.jpg)

**1. 进程**

硬盘中的代码程序加载入内存，CPU执行程序的每一条指令，这个**运行中的程序**，就是进程。

<img src="C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\并行与并发.png" alt="image-20250226100229154" style="zoom:50%;" />



**进程的状态**

![七种状态变迁](.\img\进程管理\进程七中状态.jpg)

- 运行状态（Running）：就绪状态的进程被操作系统进程调度器选中
- 就绪状态（Ready）：时间片用完，调度器调度了其他进程进入运行状态
- 阻塞状态（Blocked）：进程等待某个事件发生
- 创建状态（New）：进程正在被创建，创建完成并初始化后，若一切就绪准备运行，就进入就绪状态
- 结束状态（Exit）：进程运行完成或出错
- 挂起状态（suspended）：若存在大量阻塞状态的进程会占用物理内存，因此引入挂起状态，虚拟内存管理将阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行时从硬盘换入物理内存。即**进程没有占用实际物理内存**
  - 就绪挂起状态：进程在外存，但只要进入内存即刻就能运行
  - 阻塞挂起状态：进程在外存并等待某个事件出现

导致进程挂起的原因还可能：

- sleep让进程间歇性挂起，设置定时器到期后唤醒进程
- 用户希望挂起程序的执行，如Ctrl+Z

java中waiting和blocked状态区别

| 特性             | 阻塞blocked                                            | 等待waiting                                         |
| ---------------- | ------------------------------------------------------ | --------------------------------------------------- |
| 发生的原因       | **外部条件导致**，如 I/O 操作、资源争用（锁等待...）等 | **线程主动进入等待**，直到被通知或条件满足          |
| 线程状态         | 线程会进入阻塞队列，无法继续执行                       | 线程进入等待队列，必须等待其他线程通知              |
| 是否主动放弃 CPU | 线程会被挂起，外部条件满足后恢复执行                   | 线程进入等待队列，必须等待其他线程通知              |
| 典型方法         | `Thread.sleep()`、I/O 操作、锁等待等                   | Object.wait()`、`Thread.join()`、`Condition.await() |
| 典型方法         | 不需要其他线程通知                                     | 需要其他线程通知，如 `notify()` 或 `notifyAll()`    |

**进程的控制结构**

**进程控制块PCB**（process control block）：进程的数据结构，是进程存在的唯一标识

包含信息：

- 进程描述信息：
  - 进程标识符pid
  - 用户标识符uid：进程归属的用户，uid主要用于共享和保护服务
- 进程控制和管理信息：
  - 进程当前状态：如new、ready、running、waiting、blocked等
  - 进程优先级：进程抢占CPU优先级
- 资源分配清单：关于内存地址空间和虚拟地址空间的信息，所打开的文件的列表、所使用的I/O设备信息
- CPU相关信息：CPU寄存器的值，用于进程上下文切换保持CPU状态信息

PCB通过链表组织，相同状态的进程链在一起，组成各种队列

- 就绪队列
- 阻塞队列
- 运行队列：在单核CPU系统只有一个运行指针

除了链表组织，还能将不同状态进程组织在不同**索引表**中，索引表项执行相应PCB。

一般选择链表，因为进程创建、销毁使用链表更灵活。

**进程的控制**

1. 创建进程
   - 为新进程分配⼀个唯⼀的进程标识号，并申请⼀个空白的 PCB，PCB 是有限的，若申请失败则创建 失败； 
   - 为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；
   - 初始化 PCB； 
   - 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；
2. 终止进程：正常结束、异常结束、外界干预（kill信号）
   - 查找需要终⽌的进程的 PCB；
   -  如果处于执⾏状态，则⽴即终⽌该进程的执⾏，然后将 CPU 资源分配给其他进程；
   -  如果其还有⼦进程，则应将其所有⼦进程终⽌；
   -  将该进程所拥有的全部资源都归还给⽗进程或操作系统；
   -  将其从 PCB 所在队列中删除；
3. 阻塞进程
   - 找到将要被阻塞进程标识号对应的 PCB； 
   - 如果该进程为运⾏状态，则保护其现场，将其状态转为阻塞状态，停⽌运⾏； 
   - 将该 PCB 插⼊到阻塞队列中去；
4. 唤醒进程
   - 在该事件的阻塞队列中找到相应进程的 PCB；
   - 将其从阻塞队列中移出，并置其状态为就绪状态；
   - 把该 PCB 插⼊到就绪队列中，等待调度程序调度；

**进程的上下文切换**

一个进程切换到另一个进程运行

CPU上下文切换：CPU的上下文是其寄存器和程序计数器，切换将保存前一个任务的CPU上下文，然后加载新任务的上下文。

任务包括进程、线程、中断，因此CPU上下文切换可分成：进程上下文切换、线程上下文切换、中断上下文切换。

**进程由内核管理和调度**，因此进程切换只发生在**内核态**。

进程切换的**上下文**包含虚拟内存、栈、全局变量等用户空间资源，和内核堆栈、寄存器等内核空间资源。上下文保存在**PCB**中。

进程上下文切换场景：

- 公平调度时间片用完，进程从运行状态变为就绪队列
- 进程在系统资源不足时被挂起
- 进程sleep主动挂起
- 高优先级任务抢占，而被挂起
- 硬件中断



**2. 线程**

进程出现之后更小的独立运行的基本单元

**为什么使用线程？**

单进程内多个任务函数串行执行，存在一些问题（如视频数据获取、解码、播放，播放会卡顿，且资源使用率不高），如果将多个任务改成多进程则要解决进程间通信，且系统开销大（分配资源、创建PCB、回收资源、撤销PCB、进程切换保存上下文等）。

采用线程Thread，线程间并发运行，共享相同的地址空间。

**什么是线程？**

线程是进程中一条执行流程，同一个进程内的多个线程间共享代码段、数据段、打开文件等资源，线程各有一套独立的寄存器和栈，以确保线程控制流独立。

<img src="C:\Users\hp-pc\AppData\Roaming\Typora\typora-user-images\image-20250226143150568.png" alt="image-20250226143150568" style="zoom:50%;" />

线程的优点：

- ⼀个进程中可以同时存在多个线程；
- 各个线程之间可以并发执⾏；
- 各个线程之间可以共享地址空间和⽂件等资源；

线程的缺点：

- 当进程中的⼀个线程崩溃时，会导致其所属进程的所有线程崩溃。举个例⼦，对于游戏的⽤户设计，则不应该使⽤多线程的⽅式，否则⼀个⽤户挂了，会影响其他同个进程 的线程

  > 一般情况下，如果一个线程崩溃，那么整个进程很可能会崩溃。这是因为线程之间共享地址空间，一个线程的崩溃可能导致内存的不确定性，进而影响到其他线程的执行。为了保证进程的稳定性和安全性，操作系统往往会选择终止整个进程。然而，并非所有的线程崩溃都会导致整个进程的崩溃，有些线程崩溃可能只是局部性的问题。此外，一些编程语言和操作系统提供了一些机制来处理线程崩溃的情况。通过合理的异常处理和监控机制，我们可以更好地处理线程崩溃的情况，提高程序的稳定性和可靠性。

**线程与进程的比较**

- 进程是资源分配的单位，线程是CPU调度的单位
- 进程拥有完整的资源平台，线程只独享必不可少的资源（寄存器、栈）
- 线程具有运行、就绪、阻塞三种基本状态，同样具有状态间的转换关系
- 线程能减少并发执行时间和空间开销
  - 创建上，线程比进程快，不涉及资源管理信息（内存、文件等），共享进程的资源
  - 终止上，线程比进程快，需要释放的资源相对少很多
  - 切换快，线程具有相同地址空间（虚拟内存共享），同进程的线程具有同一个页表，切换线程无需切换页表
  - 交互效率高，同进程的线程间共享内存和文件资源，数据传递不经过内核

**线程的上下文切换**

操作系统的任务调度对象是线程，进程只是给线程提供虚拟内存、全局变量等资源

当进程只有一个线程（主线程）时，可以认为进程等于线程；有多线程时，线程共享虚拟内存、全局变量等资源，上下文切换不需修改，只保存切换寄存器、栈等私有数据。

**线程的实现**

三种线程实现方式：

- 用户线程（User Thread）：在⽤户空间实现的线程，不是由内核管理的线程，是由**⽤户态的线程管理库**来完成线程的管理（创建、终止、同步、调度等），线程控制块TCB（Thread Control Block）也由库实现，操作系统看不见TCB，不直接参与。

  多个用户线程对应同一个内核线程

  ![image-20250226151352901](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\用户线程.png)

  | 优                                                           | 缺                                                           |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 1.进程有私有的TCB列表，TCB由用户级线程库函数维护，可用于不支持线程技术的操作系统 | 1.操作系统不参与线程调度，用户线程若是发起系统调用而被阻塞，其他进程包含的用户线程也不能执行 |
  | 2.用户线程切换由线程库函数完成，无需用户态和内核态的切换，速度快 | 2.用户线程运行后，除非主动交出CPU所有权，否则进程的其他线程也无法运行，用户态的线程没有权限打断当前运行中的线程，只有操作系统有 |
  |                                                              | 3.时间片分配给进程，多线程执行，各线程得到的时间片较少       |

- 内核线程（Kernel Thread）：在内核中实现的线程，是由**内核管理**的线程，TCB于操作系统中，线程创建、终止、管理都有操作系统负责。

  一个用户线程对应一个内核线程

  ![image-20250226152314852](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\内核线程.png)

  | 优                                                           | 缺                                                   |
  | ------------------------------------------------------------ | ---------------------------------------------------- |
  | 1.进程中的一个内核线程因系统调用被阻塞，不会影响其他内核线程的执行 | 1.由内核维护进程和线程的上下文信息，如PCB和TCB       |
  | 2.时间片分配给线程，因此多线程的进程获得更多CPU运行时间      | 2.线程创建、终止和切换都由系统调用完成，系统开销较大 |

- 轻量级进程（LightWeight Process）：**内核⽀持的⽤户线程，一个进程可以有一个或多个LWP，每个LWP跟内核线程一对一**

  LWP只能由**内核管理**，像普通进程一样被调用，Linux内核是支持LWP的典型例子。

  在⼤多数系统中，**LWP与普通进程的区别也在于它只有⼀个最⼩的执⾏上下⽂和调度程序所需的统计信息**。⼀般来说，⼀个进程代表程序的⼀个实例，⽽ LWP 代表程序的执⾏线程，因为⼀个执⾏线程不像进程 那样需要那么多状态信息，所以 LWP 也不带有这样的信息。

  LWP之上使用用户线程，对应关系

  ![image-20250226153755869](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\轻量级进程.png)

  - 1:1模式：如进程4，实现并行，一个LWP阻塞不影响其他LWP，但一个用户线程就要对应到一个内核线程，创建线程开销大
  - N:1模式：如进程2，线程管理由用户空间完成，用户线程切换效率高，但用户线程阻塞会影响其他用户线程，也无法充分利用多核CPU
  - M:N模式：进程3，两级控制，大部分线程的上下文切换在用户空间，且多个内核线程充分利用多核CPU
  - 组合模式：进程5，结合1:1模型和M:N模型，开发人员根据不同应用特点调节内核线程数目达到物理并行和逻辑并行的最佳方案

**3. 调度**

调度程序scheduler在操作系统中选择一个进程运行

**调度时机**

进程从运行状态到另一个状态会触发一次调度

- 就绪态->运行态：进程被创建后进入就绪态，操作系统从就绪队列选
- 运行态->阻塞态：进程因I/O事件而阻塞
- 运行态->结束态：进程结束，操作系统从就绪队列选

硬件时钟会周期性中断，根据处理时钟中断可将调度算法分为两种：

- 非抢占式调度算法：进程阻塞或结束才会调度另一个进程
- 抢占式调度算法：时间片机制，进程时间片末尾发生时钟中断，进程被挂起，调度程序从就绪队列选另一个进程

**调度原则**

原则一：为提高**CPU利用率**，I/O事件导致CPU空闲，调度程序要从就绪队列选一个进程运行

原则二：要提升**系统吞吐率**（单位时间完成进程数量），调度程序要权衡长任务和短任务进程的运行完成数量

原则三：要避免进程的等待时间很长而运行时间很短（**周转时间**长，运行+阻塞）

原则四：就绪队列中的进程的**等待时间**要考虑

原则五：交互式较强的应用，**响应时间**要考虑

**调度算法**

单核CPU系统常见调度算法

- 先来先服务算法（First Come First Served, FCFS）：非抢占式。长作业先运行，则后头的短作业等待时间长。适合CPU繁忙型作业的系统，不适合I/O繁忙型作业的系统

- 最短作业优先调度算法（Shortest Job First, SJF）：若就绪队列有很多短作业，长作业将不断被退后，长期不被运行

- 高响应比优先调度算法（Highest Response Ratio Next, HRRN）：权衡长短作业，响应比优先级=(等待时间+要求服务时间)/要求服务时间，每次调度时计算响应比优先级，最高的进程执行。要求服务时间相同，等待时间长的优先，等待时间相同，要求服务时间短（短任务）的优先。

- 时间片轮转调度算法（Round Robin, RR）：时间片太短会造成过多进程上下文切换，降低CPU效率；太长则导致对短作业的响应时间变长。20-50ms适中

- 最高优先级调度算法（Highest Priority First，HPF）：就绪队列最高优先级进程先执行。优先级分静态优先级（创建进程时就确定，之后都不变）和动态优先级（进程运行时间增加则降低优先级，进程在就绪队列等待时间增加则升高优先级）。处理优先级高的方法分抢占式（就绪队列出现优先级高的进程，当前进程挂起，调度高的进程）和非抢占式（运行完当前进程后再选最高优先级的执行）。不过低优先级可能永远不会执行

- 多级反馈队列调度算法（Multilevel Feedback Queue）：综合并发展时间片轮转算法和最高优先级算法，多个就绪队列优先级从高到低，优先级越高时间片越短。新进程放入第一级队列末尾，先来先服务，若在第一级队列规定时间内没运行完，则放入第二级队列末尾，以此类推直至完成。当高优先级队列空了才执行低优先级队列的进程。有新进程进入优先级高的队列，则停止当前运行进程并将进程移入原队列末尾，转去执行高优先级的进程。

  ![image-20250226224803930](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\多级反馈队列调度算法.png)

### 5.2 进程间有哪些通信方法？

![img](.\img\进程管理\进程间通信提纲.jpg)

进程的用户空间独立，而内核空间共享，进程间通信需要通过内核。

![img](.\img\进程管理\进程空间.jpg)

**1. 管道**

**类型**

- 匿名管道：命令行的`|`，用完就销毁，传输单向。例`ps | grep bash`。

- 命名管道：也叫FIFO，数据先进先出，通过`mkfifo`命令创建，`mkfifo myPipe`，管道以文件形式存在（Linux一切皆文件），文件类型`p`。一端往管道写数据会被阻塞，直到管道数据都被读完才正常退出。

**优缺**

- 缺：**管道通信效率低，不适合进程间频繁交换数据**。
- 优：简单，容易得知管道数据被其他进程读取了。

**原理**

- 匿名管道通过系统调用`int pipe(int fd[2])`创建，`fd[0]`为管道的读取端描述符，`fd[1]`为写入端描述符。匿名管道是特殊文件，只存在于内存，不存在于文件系统。

- 匿名管道跨进程通信，通过`fork`创建子进程，和父进程共享文件描述符，则两个进程都各有两个`fd[0]`和`fd[1]`。由于管道只能一端写入一端读出，为了避免混乱，各保留一个`fd`，一个进程负责写入，一个进程负责读出。如果需要双向通信则创建两个管道。

  <img src=".\img\进程管理\管道-pipe-fork-单向通信.jpg" alt="img" style="zoom:50%;" />

- 在shell里执行`A | B`命令时，A和B都是shell创建的子进程，之间不存在父子关系，则是通过shell父进程将两个fd都关闭，A和B子进程各自保留一个fd。

  <img src=".\img\进程管理\管道-pipe-shell.jpg" alt="img" style="zoom:50%;" />

- 匿名管道通信范围是存在父子关系的进程，由于没有实体文件，只能通过fork来复制父进程的fd文件描述符来达到通信目的。

- **命名管道可以在不相关的进程间通信**，提前创建管道类型的文件，在进程中使用该设备文件即可。

- 管道是内核中一串缓存，从内核读写。通信数据遵循先进先出原则，不支持lseek之类的文件定位操作。

- 管道传输的数据是无格式的流，大小受限。

**2. 消息队列**

**原理**

- 进程间通信，进程A将数据放入对应消息队列即可返回，进程B需要时再去读取。
- 消息队列保存在内核中的**消息链表**，数据为一个个独立的数据单元（消息体、消息块）。消息体是用户自定义的数据类型，由通信双方约定好。消息体固定大小，不像管道是无格式的字节流。进程从消息队列读取了消息体，内核就会将消息体删除。
- 生命周期：消息队列的生命周期随内核，直到释放消息队列或关闭操作系统。匿名管道的生命周期随进程。

**优缺**

- 优：通信效率高，适合进程间频繁交换数据。
- 缺：通信不及时；附件有大小限制。

消息队列不适合较大数据的传输，Linux内核有两个宏定义`MSGMAX`和`MSGMNB`，以字节为单位，分别定义一条消息的最大长度和消息队列的最大长度。

消息队列通信过程中，存在用户态和内核态间的数据拷贝开销。

**3. 共享内存**

**原理**

- 两个进程分别划出一块虚拟地址空间，映射到相同的物理内存中，实现共享。（内存管理中虚拟内存技术，是为进程分配独立的虚拟内存空间，映射到不同物理内存）

<img src=".\img\进程管理\共享内存.jpg" alt="img" style="zoom:50%;" />

**优缺**

- 优：无需用户态与内核态间的消息拷贝，进程间通信速度快。
- 缺：存在多进程访问冲突。

**4. 信号量**

**作用**：保护共享内存，确保共享的资源在任意时刻只能被一个进程访问。

**原理**

- 信号量实际上是一个整型计数器，主要用于实现进程间的互斥与同步，而非缓存进程间通信的数据。

- 信号量表示资源的数量，控制信号量通过两种原子操作：**P操作**，信号量-1，减后信号量**<0**则表明资源已被占用，进程阻塞等待，否则进程进行运行；**V操作**，信号量+1，加后信号量**<=0**则表明当前有阻塞的进程，会将进程唤醒运行，否则说明没有进程被阻塞。
- P操作在进入共享资源前使用，V操作在离开共享资源后使用，必须成对出现。

**互斥信号量**

进程互斥访问共享内存，**初始化信号量为1**。进程A访问共享内存前执行P操作，信号量变为0，表示共享资源可用，但此时进程B也想访问，执行P操作后信号量为-1，则阻塞。进程A访问完共享内存后执行V操作，信号量为0，唤醒阻塞中的进程B。

<img src=".\img\进程管理\信号量-互斥.jpg" alt="img" style="zoom:50%;" />

**同步信号量**

进程间同步，**初始信号量为0**。如果B先A执行，执行P操作后，信号量为-1，阻塞。等到A生产完数据后执行V操作，信号量为0，唤醒进程B。

<img src=".\img\进程管理\信号量-同步.jpg" alt="img" style="zoom:50%;" />

**5. 信号**

上述进程间通信都是常规状态下的工作模式，对于异常情况下的工作模式，通过**信号**通知进程。

Linux中有各种信号以响应各种事件，`kill -l`查看。`Ctrl+C`产生`SIGINT`信号，以终止进程；`Ctrl+Z`产生`SIGTSTP`信号，停止进程但未结束。

进程后台运行，通过`kill`命令向进程发送信号，如`kill -9 1050`表示向PID为1050的进程发送`SIGKILL`信号，立即结束进程。

因此信号事件来源有硬件来源（Ctrl+C）和软件来源（kill命令）。

信号是进程间通信机制中**唯一的异步通信机制**，可以在任意时刻发送信号给进程。

用户进程对信号有几种处理方式：

- 执行默认操作
- 捕捉信号：为信号定义一个自定义的信号处理函数
- 忽略信号：不处理某些信号，但`SIGKILL`和`SIGSTOP`无法被捕捉和忽略。

**6. Socket**

跨网络与不同主机上进程间通信，需要Socket通信。同时Socket通信也可以在同主机进程间通信。

系统调用`int socket(int domain, int type, int protocal)`

- domain指定协议族，AF_INET用于IPV4，AF_INET6用于IPV6，AF_LOCAL/AF_UNIX用于本机。
- type指定通信特性，SOCK_STREAM字节流对应TCP，SOCK_DGRAM数据包对应UPD，SOCK_RAW原始套接字。
- protocal指定通信协议，基本弃用。

**TCP协议通信的socket编程模型**

![img](.\img\进程管理\TCP编程模型.jpg)

服务端有两个socket，监听socket、已完成连接socket。

**UDP协议通信的socket编程模型**

<img src=".\img\进程管理\UDP编程模型.jpg" alt="img" style="zoom:50%;" />

没有客户端和服务端概念，只要有一个socket多台机器就可以通信，每个UDP的socket都要bind。

每次通信调用sendto和recvfrom都要传入目标主机的IP地址和端口。

**针对本地进程间通信的socket编程模型**

本地socket编程接口和IPv4、IPv6的一致，支持字节流和数据包两种协议，实现效率大大高于IPv4和IPv6的字节流、数据包socket实现。

bind时不像TCP和UDP要绑定IP地址和端口，而是**绑定一个本地文件**。

**7. 总结**



### 5.3 多线程冲突了怎么办？

![img](.\img\进程管理\多线程冲突提纲.jpg)

**1. 竞争与协作**

操作系统为每个进程创建巨大、私有的虚拟内存，这些地址空间**复用**物理内存或磁盘

一个程序只有一个执行流程，即单线程的，有多个执行流程，则是多线程程序

<img src="C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\多线程冲突案例.png" alt="image-20250227092151472" style="zoom:50%;" />

**互斥的概念**

**竞争条件**（race condition）下，多线程竞争共享变量，上下文切换使结果存在**不确定性**（indeterminate）。

**临界区**（critical section），访问共享资源的代码片段，一定不能被多线程同时执行。

要保证临界区代码**互斥**（mutualexclusion）的，保证临界区没有多个线程同时在执行。

多进程竞争共享资源时也可以使用互斥的方法。

![image-20250227092900001](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\互斥.png)

**同步的概念**

并发进程/线程在一些关键点上相互制约的等待与互通信息，即**进程/线程同步**。

**2. 互斥与同步的实现和使用**

锁可实现互斥，信号量可实现互斥和同步

**锁**

加锁、解锁来互斥

根据实现不同分：

- 忙等待锁

  **测试和置位指令（Test-and-Set）**是**原子操作指令**（要么全部执行，要么都不执行），将指针内容更新为新值并返回旧值，以C代码表示就如下

  ```c
  int TestAndSet(int *old_ptr, int new) 
  {
  	int old = *old_ptr;
  	*old_ptr = new;
  	return old
  }
  ```

  **忙等待锁是由Test-and-Set指令实现**

  ```c
  typedef struct lock_t {
      int flag;
  } lock_t;
  void init(lock_t *lock)
  {
      lock->flag = 0;
  }
  void lock(lock_t *lock)
  {
  	while(TestAndSet(&lock->flag, 1) == 1)
      ; do nothing
  }
  void unlock(lock_t *lock)
  {
      lock->flag = 0;
  }
  ```

  获取锁的两种情况

  - 线程调用lock()时，没有其他线程持有锁（flag=0），则跳过while，且flag设置为1标志锁已经被持有。当离开临界区，unlock()将flag清0。
  - 线程调用lock()时，已经有其他线程持有锁（flag=1），则在while中循环（**忙等**），当有其他线程调用unlock()释放锁，flag=0，线程才跳出while，且flag置1，进入临界区。

  忙等待锁如果获取不到锁，线程将一直while循环，也称**自旋锁**（spin lock）。

  忙等待锁在单处理器上需要抢占式的调度器，否则线程自选永远不会释放CPU。

- 无忙等待锁

  获取不到锁，不用自旋，线程会被放入锁的等待队列，然后执行调度程序将CPU让给其他线程。

  ```c
  typedef struct lock_t {
  	int flag;
      queue_t *q; // 等待队列
  } lock_t;
  void init(lock_t *lock) 
  {
      lock->flag = 0;
      queue_init(lock->q);
  }
  void lock(lock_t *lock) 
  {
      while(TestAndSet(&lock->flag, 1) == 1)
      {
          保存现在运行线程TCB;
  		将TCB插入等待队列;
          设置线程为等待状态;
          调度程序;
      }
  }
  void unlock(lock_t *lock) 
  {
      if(lock->q != NULL)
      {
          移除等待队列的队头元素;
          将该线程TCB插入就绪队列;
          设置线程为就绪状态;
      }
      lock->flag = 0;
  }
  ```

**信号量**

信号量表示资源的数量，对应变量sem（整型），通过P和V两个原子操作的系统调用函数来控制信号量，P、V成对出现。

- P操作：sem-1，if sem<0，阻塞等待
- V操作：sem+1，if sem<=0，唤醒等待

```c
typedef struct sem_t {
    int sem;	// 资源个数
    queue_t *q; // 等待队列
} sem_t;

void init(sem_t *s, int sem) 
{
    s->sem = sem;
    queue_init(s->q);
}

void P(sem_t *s)
{
    s->sem--;
    if(s->sem < 0) 
    {
        1. 保留调用线程CPU线程;
        2. 将该线程TCB插入s等待队列;
        3. 设置该线程为等待状态;
        4. 执行调度程序;
    }
}

void V(sem_t *s)
{
    s->sem++;
    if(s->sem <= 0) 
    {
        1. 移除s等待队列的对首元素;
        2. 将该线程TCB插入就绪队列;
        3. 设置该线程为就绪状态;
    }
}
```

PV操作函数由操作系统管理和实现，因此具备原子性。

信号量能够实现临界区互斥访问控制（sem初始值1，临界区前P，临界区后V，只存在1、0、-1三个值），也可以实现线程间事件同步（sem初始值0，先P的线程会等待V的线程，P在V完成后执行完）。

**生产者-消费者问题**

![image-20250227121344992](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\生产者-消费者问题.png)

任意时刻只能有一个生产者或消费者访问缓冲区，需要**互斥**；缓冲区空时消费者等待，缓冲区满时生产者等待，需要**同步**。

设置三个信号量：

- 互斥信号量mutex：初始值1
- 资源信号量fullBuffers：初始值0，用于消费者询问是否有数据
- 资源信号量emptyBuffers：初始值n，用于生产者询问是否有空位

```c
#define N 100
semaphore mutex = 1;
semaphore emptyBuffers = N;
semaphore fullBuffers = 0;

void producer()
{
    P(emptyBuffers);
    P(mutex);
    写数据到缓冲区
    V(mutex);
    V(fullBuffers);
}

void consumer()
{
    P(fullBuffers);
    P(mutex);
    从缓冲区读数据;
    V(mutex);
    V(emptyBuffers);
}
```



**3. 经典同步问题**

**哲学家就餐问题**

问题描述：

- 5 个⽼⼤哥哲学家，闲着没事做，围绕着⼀张圆桌吃⾯；
- 巧就巧在，这个桌⼦只有 5 ⽀叉⼦，每两个哲学家之间放⼀⽀叉⼦；
- 哲学家围在⼀起先思考，思考中途饿了就会想进餐；
- 奇葩的是，这些哲学家要两⽀叉⼦才愿意吃⾯，也就是需要拿到左右两边的叉⼦才进餐；
- 吃完后，会把两⽀叉⼦放回原处，继续思考；

方案一：

![image-20250227215755717](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\哲学家问题-方案一.png)

极端问题：五个哲学家都同时拿起左边的叉子，导致死锁

方案二：

![image-20250227215929689](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\哲学家问题-方案二.png)

防止方案一死锁，拿叉子前加互斥信号量，不过某个时刻只能有一个哲学家在进餐

方案三

![image-20250227220121524](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\哲学家问题-方案三.png)

偶数编号哲学家先拿左边叉子后拿右边叉子，奇数编号哲学家先拿右边叉子后拿左边叉子，同时可以有两个哲学家进餐

方案四

用数组state记录每一位哲学家在进餐、思考还是饥饿状态（正在试图拿叉子），一个哲学家只有左右两个邻居没有进餐才进入进餐状态

![image-20250227220515684](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\哲学家问题-方案四.png)

**读者-写者问题**

问题描述：

- 【读-读】允许
- 【读-写】互斥
- 【写-写】互斥

方案一

信号量解决

- 信号量wMutex：控制写操作的互斥信号量，初始值1
- 读者计数rCount：正在读操作的读者个数，初始值0
- 信号量rCountMutex：控制对rCount读者计数器的互斥修改，初始值1

![image-20250227221157518](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\读写问题-方案一.png)

读者优先，若有读者不停进入，则写者会处于饥饿状态。

方案二

写者优先策略

- 只要有写者准备要写⼊，写者应尽快执⾏写操作，后来的读者就必须阻塞；
- 如果有写者持续不断写⼊，则读者就处于饥饿；

![image-20250227222303970](C:\Users\hp-pc\AppData\Roaming\Typora\typora-user-images\image-20250227222303970.png)

方案三

公平策略

- 优先级相同
- 写者、读者互斥访问
- 只能一个写者访问临界区
- 可以有多个读者同时访问临界资源

![image-20250227222556941](C:\Users\hp-pc\AppData\Roaming\Typora\typora-user-images\image-20250227222556941.png)



### 5.4 怎么避免死锁？

**1. 死锁的概念**

两个线程为了保护两个不同的共享资源而使用互斥锁，但两个互斥锁使用不当导致**两个线程都在等待对方释放锁**，造成死锁。

死锁需要满足四个条件

- **互斥条件**：多个线程不能同时使用同一个资源

  ![image-20250228141518823](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\死锁四个条件-互斥条件.png)

- **持有并等待条件**：持有资源A且等待资源B，资源A不会被释放

  ![image-20250228141732631](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\死锁四个条件-持有并等待条件.png)

- **不可剥夺条件**：资源在线程使用完前不会被其他线程获取

  ![image-20250228142026777](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\死锁四个条件-不可剥夺条件.png)

- **环路等待条件**：两个线程获取资源的顺序构成了环形链

  ![image-20250228142108435](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\死锁四个条件-环路等待条件.png)

**2. 模拟死锁问题的产生**

**3. 利用工具排查死锁问题**

pstack、gdb工具定位死锁，`pstak <pid>`可查看每个线程的函数调用过程，`gdb -p <pid>`查看线程具体等待的锁（info thread、thread n、bt、frame n、p mutex_A等等）。

**4. 避免死锁问题的发生**

破坏四个条件之一即可，最常见是使用**资源有序分配法**（两个线程对两个不同资源的获取顺序一致）来破坏环路等待条件。



### 5.5 什么是悲观锁、乐观锁？

![img](.\img\进程管理\锁之提纲.png)

不同锁适合不同场景，选择锁需要考虑加锁成本开销、分析业务场景访问共享资源方式、考虑并发访问共享资源冲突概率。

**1. 互斥锁与自旋锁**

最底层的两种锁是互斥锁和自旋锁，很多高级锁都基于它们实现。

互斥锁和自旋锁区别在**加锁失败后处理方式**不同

- 互斥锁加锁失败，线程释放CPU
- 自旋锁加锁失败，线程忙等待

互斥锁是一种**独占锁**，只被一个线程独占，其他线程加锁时被阻塞（线程释放CPU，由内核实现）。互斥锁加锁失败会从用户态陷入内核态，由内核切换线程，存在两次线程上下文切换的性能开销成本（运行->睡眠、睡眠->就绪）。如果锁住的代码执行时间很短，就不该用互斥锁而是自旋锁。

![image-20250228215041323](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\互斥锁工作.png)

自旋锁通过CPU提供的**CAS函数**（Compare And Swap），在用户态完成加锁和解锁，不会有线程上下文切换。CAS函数是原子指令（查看锁是否空闲，空闲就将锁设置为当前线程持有，两步要么一起完成，要不一起不完成）。加锁失败会忙等待（可用while循环等待实现，不过最好用CPU的**PAUSE**指令实现）。

单核CPU上用自旋锁需要抢占式的调度器，否则自旋锁会导致线程永远不会放弃CPU。

自旋锁开销少，多核系统下一般不会主动切换线程，**适合异步、协程等在用户态切换请求的编程方式**。

**2. 读写锁**

读写锁适用于能明确区分读操作和写操作的场景

写锁是独占锁，读锁是共享锁。适合读多写少的场景。

根据实现分读优先锁、写优先锁、公平读写锁

![image-20250228223938121](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\读写锁-读优先锁.png)

![image-20250228224004222](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\读写锁-写优先锁.png)

公平读写锁较简单的实现方法：用队列把获取锁的线程排队，按先进先出原则加锁。

**3. 乐观锁与悲观锁**

互斥锁、自旋锁、读写锁都是悲观锁，认为修改共享资源概率高，**访问资源前要先上锁**。

**乐观锁**做事乐观，假定冲突率低，在先改完共享资源后再验证是否也有其他线程在这段时间内也修改了资源，没有则操作完成，否则放弃本次操作。乐观锁不加锁，是**无锁编程**。案例：在线文档，先让用户编辑文档，下载文档时记录下文档版本号，提交修改时带上版本号，如果和服务器上的一致则修改成功，否则提交失败。如SVN和Git等版本控制工具也是用了乐观锁的思想。不过冲突后重试成本非常高，因此只在冲突非常低的场景使用。

### 5.6 一个进程最多可以创建多少个线程？

![image-20250228230800726](C:\Users\hp-pc\Desktop\实习备战记\计算机系统\img\进程管理\虚拟地址空间.png)

一个进程最多创建线程数由两方面决定：

- 进程的虚拟内存空间上限：32位系统用户空间3G，如果分配给每个线程的栈空间10M，就只能创建300左右个线程，64位系统用户空间128T理论能创建1000多万个。
- 系统参数限制：三个内核参数限制，`proc/sys/kernel/threads-max`系统支持的最大线程数，默认14553；`proc/sys/kernel/pid_max`系统全局PID号数量限制，每个线程或进程都有ID，默认数量32768；`proc/sys/kernel/max_map_count`限制一个进程拥有的VMA（虚拟内存区域）数量，默认65530。

### 5.7 线程崩溃了，进程也会崩溃吗？

**1. 线程崩溃，进程一定会崩溃吗**

如果线程因为非法访问内存（对只读内存写数据、访问了进程没有权限访问的地址空间（如内核空间）、访问不存在的内存）引起崩溃，进程也会崩溃，因为进程内多线程共享地址空间，**非法访问会导致内存的不确定性**，进而影响其他线程，操作危险。非法访问内存统一报Segment Fault错误，导致进程崩溃。

**2. 进程是如何崩溃的-信号机制简介**

信号机制

- CPU执行正常的进程指令
- 调用kill系统调用向进程发送信号（假设11，SIGSEGV非法访问内存）
- 进程收到信号后，CPU暂停程序运行，将控制权转交给操作系统
- 操作系统执行相应的信号处理函数，一般执行完后就让进程退出

可以注册自己的信号处理函数，让进程回收资源优雅退出。当然也可以选择忽略信号，恢复进程执行。

**3. 为什么线程崩溃不会导致JVM进程崩溃**

java常见非法访问内存的错误如StackoverflowError或NPE，是在出错时调用自定义的信号处理函数。

**4. openJDK源码解析**





## 六、调度算法

### 6.1 进程调度/页面置换/磁盘调度算法

![本文提纲](.\img\调度算法\调度算法提纲.png)

**1. 进程调度算法**

**先来先服务调度算法**

**最短作业优先调度算法**

**高响应比优先调度算法**

**时间片轮转调度算法**

**最高优先级调度算法**

**多级反馈队列调度算法**

**2. 内存页面置换算法**

![虚拟内存的流程](.\img\调度算法\虚拟内存管理流程.png)

**最佳页面置换算法**

**先进先出置换算法**

**最近最久未使用的置换算法**

**时钟页面置换算法**

**最不常用算法**



**3. 磁盘调度算法**

**先来先服务**

**最短寻道时间优先**

**扫描算法**

**循环扫描算法**

**LOOK与C-LOOK算法**



## 七、文件系统

![img](.\img\文件系统\文件系统-提纲.png)

**1. 文件系统的基本组成**

**2. 虚拟文件系统**

![img](.\img\文件系统\虚拟文件系统.png)

**3. 文件的使用**

**4. 文件的存储**

**连续空间存放方式**

**非连续空间存放方式**

**Unix文件的实现方式**

**5. 空闲空间管理**

**空闲表法**

**空闲链表法**

**位图**

**6. 文件系统的结构**

**7. 目录的存储**

**8. 软链接和硬链接**

**9. 文件I/O**

**缓冲与非缓冲I/O**

**直接与非直接I/O**

**阻塞与非阻塞I/O VS 同步与异步I/O**



### 7.2 进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？

**1. Page Cache**

**Page Cache是什么？**

**如何查看系统的Page Cache？**

**page与Page Cache**

**Swap与缺页中断**

**Page Cache与buffer cache**

**Page Cache与预读**

**2. Page Cache与文件持久化的一致性&可靠性**

**3. Page Cache的优劣势**

**Page Cache的优势**

**Page Cache的劣势**



## 八、设备管理

### 8.1 键盘敲入A字母时，操作系统期间发生了什么？

![img](.\img\设备管理\设备管理.png)

**1. 设备控制器**

**2. I/O控制方法**

**3. 设备驱动程序**

**4. 通用块层**

**5. 存储系统I/O软件分层**

**6. 键盘敲入字母时，期间发生了什么？**





## 九、网络系统

### 9.1 什么是零拷贝？

![img](.\img\网络系统\零拷贝提纲.png)

**1. 为什么要有DMA技术？**

**2. 传统的文件传输有多糟糕？**

**3. 如何优化文件传输的性能？**

**4. 如何实现零拷贝？**

**mmap+write**

**sendfile**

**使用零拷贝技术的项目**

**5. PageCache有什么作用？**

**6. 大文件传输用什么方式实现？**




### 9.2 I/O多路复用：select/poll/epoll

![img](.\img\网络系统\多路复用提纲.png)

**1. 最基本的Socket模型**

**2. 如何服务更多的用户？**

**3. 多进程模型**

**4. 多线程模型**

**5. I/O多路复用**

**6. select/poll**

**7. epoll**

**边缘触发和水平触发**



### 9.3 高性能网络模式：Reactor和Proactor

![img](.\img\网络系统\reactor提纲.jpeg)

**1. 演进**

**2. Reactor**

**单Reactor单进程/线程**

**单Reactor多线程/多进程**

**多Reactor多进程/线程**

**3. Proactor**



### 9.4 什么是一致性哈希？

![img](.\img\网络系统\一致性哈希提纲.png)

**1. 如何分配请求？**

**2. 使用哈希算法有什么问题？**

**3. 使用一致性哈希算法有什么问题？**

**4. 如何通过虚拟节点提高均衡度？**



## 十、Linux命令

### 10.1 如何查看网络的性能指标？

![img](.\img\Linux命令\网络提纲.png)

**1. 性能指标有哪些？**

**2. 网络配置如何看？**

**3. socket信息如何查看？**

**4. 网络吞吐率和PPS如何查看？**

**5. 连通性和延时如何查看？**



### 10.2 如何从日志分析PV、UV？

![img](.\img\Linux命令\提纲日志.png)

**1. 别急着开始**

**2. 慎用cat**

**3. PV分析**

**4. PV分组**

**5. UV分析**

**6. UV分组**

**7. 终端分析**

**8. 分析TOP3的请求**

